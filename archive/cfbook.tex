% The contents of this file is 
% Copyright (c) 2009-2011  Charles R. Severance, All Righs Reserved

%\documentclass[10pt,b5paper]{book}
\documentclass[11pt]{book}
% \usepackage[width=5.25in,height=7.50in,hmarginratio=3:2,vmarginratio=1:1]{geometry}
\usepackage[size=journal,gutter=0.75in,trim,bleed]{createspace}

\usepackage{pslatex}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{exercise}
\usepackage{makeidx}
\usepackage{setspace}
\usepackage{hevea}
\usepackage{alltt}
\usepackage{upquote}

\newcommand{\thetitle}{Python for Informatics: Exploring Information}
\newcommand{\theversion}{0.0.8-d3}

\makeindex

\begin{document}

\frontmatter

% LATEXONLY

\input{latexonly}

\newtheorem{ex}{Exercise}[chapter]

\begin{latexonly}

\renewcommand{\blankpage}{\thispagestyle{empty} \quad \newpage}

\thispagestyle{empty}

\begin{flushright}
\vspace*{2.0in}

\begin{spacing}{3}
{\huge Python for Informatics}\\
{\Large Exploring Information}
\end{spacing}

\vspace{0.25in}

Version \theversion

\vspace{0.5in}


{\Large
Charles Severance\\
}

\vfill

\end{flushright}

%--copyright--------------------------------------------------
\pagebreak
\thispagestyle{empty}

{\small
Copyright \copyright ~2009-2013 Charles Severance.


Printing history:

\begin{description}

\item[October 2013:] Major revision to Chapters 13 and 14
to switch to JSON and use OAuth.
Added new chapter on Visualization.

\item[September 2013:] Published book on Amazon CreateSpace

\item[January 2010:] Published book using the University of 
Michigan Espresso Book machine.

\item[December 2009:] Major revision to chapters 2-10 from
\emph{Think Python: How to Think Like
a Computer Scientist}
and writing chapters 1 and 11-15 to
produce 
\emph{Python for Informatics: Exploring Information}

\item[June 2008:] Major revision, changed title to
\emph{Think Python: How to Think Like
a Computer Scientist}.

\item[August 2007:] Major revision, changed title to
\emph{How to Think Like a (Python) Programmer}.

\item[April 2002:] First edition of \emph{How to Think Like
a Computer Scientist}.

\end{description}

\vspace{0.2in}

This work is licensed under a 
Creative Common
Attribution-NonCommercial-ShareAlike 3.0 Unported License.
This license is 
available at
\url{creativecommons.org/licenses/by-nc-sa/3.0/}.  You can 
see what the author considers commercial and non-commercial
uses of this material as well as license exemptions 
in the Appendix titled Copyright Detail.

The \LaTeX\ source for the 
\emph{Think Python: How to Think Like
a Computer Scientist}
version of this book is available from
\url{http://www.thinkpython.com}.

\vspace{0.2in}

} % end small

\end{latexonly}


% HTMLONLY

\begin{htmlonly}

% TITLE PAGE FOR HTML VERSION

{\Large \thetitle}

{\large 
Charles Severance}

Version \theversion

\setcounter{chapter}{-1}

\end{htmlonly}

\chapter{Preface}

\section*{Python for Informatics: Remixing an Open Book}

It is quite natural for academics who are continuously told to 
``publish or perish'' to want to always create something from scratch
that is their own fresh creation.   This book is an 
experiment in not starting from scratch, but instead ``re-mixing''
the book titled
\emph{Think Python: How to Think Like
a Computer Scientist}
written by Allen B. Downey, Jeff Elkner and others.

In December of 2009, I was preparing to teach
{\bf SI502 - Networked Programming} at the University of Michigan
for the fifth semester in a row and decided it was time
to write a Python textbook that focused on exploring data
instead of understanding algorithms and abstractions.
My goal in SI502 is to teach people life-long data handling 
skills using Python.  Few of my
students were planning to be professional 
computer programmers.  Instead, they
planned be librarians, managers, lawyers, biologists, economists, etc. 
who happened to want to skillfully use technology in their chosen field.

I never seemed to find the perfect data-oriented Python
book for my course so I set out 
to write just such a book.  Luckily at a faculty meeting three weeks
before I was about to start my new book from scratch over 
the holiday break, 
Dr. Atul Prakash showed me the \emph{Think Python} book which he had
used to teach his Python course that semester.  
It is a well-written Computer Science text with a focus on 
short, direct explanations and ease of learning.  

The overall book structure
has been changed to get to doing data analysis problems as quickly as
possible and have a series of running examples and exercises 
about data analysis from the very beginning.  

The chapters 2-10 are similar to the \emph{Think Python} book
but there have been major changes.  Number-oriented examples and
exercises have been replaced with data-oriented exercises.
Topics are presented in the order to needed to build increasingly
sophisticated data analysis solutions.  Some topics like {\tt try} and
{\tt except} are pulled forward and presented as part of the chapter
on conditionals.  Functions are given very light treatment until 
they are needed to handle program complexity rather introduced 
as an early lesson in abstraction.  Nearly all user-defined functions
have been removed from the example code and exercises outside Chapter 4.
The word ``recursion''\footnote{Except of course for this line.}
does not appear in the book at all.

In chapters 1 and 11-16, all of the material is brand new, focusing
on real-world uses and simple examples of Python for data analysis 
including regular expressions for searching and parsing, 
automating tasks on your computer, retrieving data across 
the network, scraping web pages for data, 
using web services, parsing XML and JSON data, and creating 
and using databases using Structured Query Language.

The ultimate goal of all of these changes is a shift from a 
Computer Science to an Informatics
focus is to only include topics into a first technology 
class that can be useful even if one chooses not to 
become a professional programmer.

Students who find this book interesting and want to further explore
should look at Allen B. Downey's \emph{Think Python} book.  Because there
is a lot of overlap between the two books,
students will quickly pick up skills in the additional
areas of technical programming and algorithmic thinking 
that are covered in \emph{Think Python}.
And given that the books have a similar writing style, you should be 
able to move quickly through \emph{Think Python} with a minimum of effort.

\index{Creative Commons License}
\index{CC-BY-SA}
\index{BY-SA}
As the copyright holder of \emph{Think Python},
Allen has given me permission to change the book's license 
on the material from his book that remains in this book
from the
GNU Free Documentation License 
to the more recent
Creative Commons Attribution --- Share Alike
license.
This follows a general shift in open documentation licenses moving 
from the GFDL to the CC-BY-SA (i.e. Wikipedia).
Using the CC-BY-SA license maintains the book's 
strong copyleft tradition while making it even more straightforward 
for new authors to reuse this material as they see fit.

I feel that this book serves an example of why open 
materials are so important to the future of education,
and want to thank Allen B. Downey and Cambridge University
Press for their forward looking decision to make the book available
under an open Copyright.   I hope they are pleased with the 
results of my efforts and I hope that you the reader are pleased with
\emph{our} collective efforts.

I would like to thank Allen B. Downey and Lauren Cowles for their help,
patience, and guidance in dealing with and resolving the copyright 
issues around this book.

Charles Severance\\
www.dr-chuck.com\\
Ann Arbor, MI, USA\\
September 9, 2013

Charles Severance is a 
Clinical Associate Professor 
at the University of Michigan School of Information.

\section*{Preface for ``Think Python''}

\subsection*{The strange history of ``Think Python''}

(Allen B. Downey)

In January 1999 I was preparing to teach an introductory programming
class in Java.  I had taught it three times and I was getting
frustrated.  The failure rate in the class was too high and, even for
students who succeeded, the overall level of achievement was too low.

One of the problems I saw was the books.  
They were too big, with too much unnecessary detail about Java, and
not enough high-level guidance about how to program.  And they all
suffered from the trap door effect: they would start out easy,
proceed gradually, and then somewhere around Chapter 5 the bottom would
fall out.  The students would get too much new material, too fast,
and I would spend the rest of the semester picking up the pieces.

Two weeks before the first day of classes, I decided to write my
own book.  
My goals were:

\begin{itemize}

\item Keep it short.  It is better for students to read 10 pages
than not read 50 pages.

\item Be careful with vocabulary.  I tried to minimize the jargon
and define each term at first use.

\item Build gradually. To avoid trap doors, I took the most difficult
topics and split them into a series of small steps. 

\item Focus on programming, not the programming language.  I included
the minimum useful subset of Java and left out the rest.

\end{itemize}

I needed a title, so on a whim I chose \emph{How to Think Like
a Computer Scientist}.

My first version was rough, but it worked.  Students did the reading,
and they understood enough that I could spend class time on the hard
topics, the interesting topics and (most important) letting the
students practice.

I released the book under the GNU Free Documentation License,
which allows users to copy, modify, and distribute the book.

\index{GNU Free Documentation License}
\index{Free Documentation License, GNU}

What happened next is the cool part.  Jeff Elkner, a high school
teacher in Virginia, adopted my book and translated it into
Python.  He sent me a copy of his translation, and I had the
unusual experience of learning Python by reading my own book.

Jeff and I revised the book, incorporated a case study by
Chris Meyers, and in 2001 we released \emph{How to Think Like
a Computer Scientist: Learning with Python}, also under
the GNU Free Documentation License.
As Green Tea Press, I published the book and started selling
hard copies through Amazon.com and college book stores.
Other books from Green Tea Press are available at
\url{greenteapress.com}.

In 2003 I started teaching at Olin College and I got to teach
Python for the first time.  The contrast with Java was striking.
Students struggled less, learned more, worked on more interesting
projects, and generally had a lot more fun.

Over the last five years I have continued to develop the book,
correcting errors, improving some of the examples and
adding material, especially exercises.  In 2008 I started work
on a major revision---at the same time, I was
contacted by an editor at Cambridge University Press who
was interested in publishing the next edition.  Good timing!

I hope you enjoy working with this book, and that it helps
you learn to program and think, at least a little bit, like
a computer scientist.

\subsection*{Acknowledgements for ``Think Python''}

(Allen B. Downey)

First and most importantly, I thank Jeff Elkner, who
translated my Java book into Python, which got this project
started and introduced me to what has turned out to be my
favorite language.

I also thank Chris Meyers, who contributed several sections
to \emph{How to Think Like a Computer Scientist}.

And I thank the Free Software Foundation for developing
the GNU Free Documentation License, which helped make
my collaboration with Jeff and Chris possible.

\index{GNU Free Documentation License}
\index{Free Documentation License, GNU}

I also thank the editors at Lulu who worked on
\emph{How to Think Like a Computer Scientist}.

I thank all the students who worked with earlier
versions of this book and all the contributors (listed
in an Appendix) who sent in corrections and suggestions.

And I thank my wife, Lisa, for her work on this book, and Green
Tea Press, and everything else, too.

Allen B. Downey \\
Needham MA\\

Allen Downey is an Associate Professor of Computer Science at 
the Franklin W. Olin College of Engineering.


\clearemptydoublepage

% TABLE OF CONTENTS
\begin{latexonly}

\tableofcontents

\clearemptydoublepage

\end{latexonly}

% START THE BOOK
\mainmatter

\chapter{Why should you learn to write programs?}

Writing programs (or programming) is a very creative 
and rewarding activity.  You can write programs for 
many reasons ranging from making your living to solving
a difficult data analysis problem to having fun to helping
someone else solve a problem.  This book assumes that 
\emph{everyone} needs to know how to program and that once 
you know how to program, you will figure out what you want 
to do with your newfound skills.  

We are surrounded in our daily lives with computers ranging 
from laptops to cell phones.  We can think of these computers
as our ``personal assistants'' who can take care of many things
on our behalf.  The hardware in our current-day computers 
is essentially built to continuously ask us the question, 
``What would you like me to do next?''.

\beforefig
\centerline{\includegraphics[height=1.00in]{figs2/pda.eps}}
\afterfig

Programmers add an operating system and a set of applications
to the hardware and we end up with a Personal Digital
Assistant that is quite helpful and capable of helping
many different things.

Our computers are fast and have vast amounts of memory and 
could be very helpful to us if we only knew the language to
speak to explain to the computer what we would like it to 
``do next''.  If we knew this language we could tell the 
computer to do tasks on our behalf that were repetitive.  
Interestingly, the kinds of things computers can do best
are often the kinds of things that we humans find boring
and mind-numbing.

For example, look at the first three paragraphs of this
chapter and tell me the most commonly used word and how
many times the word is used.  While you were able to read
and understand the words in a few seconds, counting them
is almost painful because it is not the kind of problem 
that human minds are designed to solve.  For a computer
the opposite is true, reading and understanding text 
from a piece of paper is hard for a computer to do 
but counting the words and telling you how many times
the most used word was used is very easy for the
computer:

\beforeverb
\begin{verbatim}
python words.py
Enter file:words.txt
to 16
\end{verbatim}
\afterverb
%
Our ``personal information analysis assistant'' quickly 
told us that the word ``to'' was used sixteen times in the
first three paragraphs of this chapter.

This very fact that computers are good at things 
that humans are not is why you need to become
skilled at talking ``computer language''.  Once you learn
this new language, you can delegate mundane tasks
to your partner (the computer), leaving more time 
for you to do the 
things that you are uniquely suited for.  You bring 
creativity, intuition, and inventiveness to this
partnership.  

\section{Creativity and motivation}

While this book is not intended for professional programmers, professional
programming can be a very rewarding job both financially and personally.
Building useful, elegant, and clever programs for others to use is a very
creative activity.  Your computer or Personal Digital Assistant (PDA) 
usually contains many different programs from many different groups of 
programmers, each competing for your attention and interest.  They try 
their best to meet your needs and give you a great user experience in the
process.   In some situations, when you choose a piece of software, the 
programmers are directly compensated because of your choice.

If we think of programs as the creative output of groups of programmers,
perhaps the following figure is a more sensible version of our PDA:

\beforefig
\centerline{\includegraphics[height=1.00in]{figs2/pda2.eps}}
\afterfig

For now, our primary motivation is not to make money or please end-users, but
instead for us to be more productive in handling the data and 
information that we will encounter in our lives.
When you first start, you will be both the programmer and end-user of
your programs.  As you gain skill as a programmer and
programming feels more creative to you, your thoughts may turn
toward developing programs for others.

\section{Computer hardware architecture}
\index{hardware}
\index{hardware!architecture}

Before we start learning the language we 
speak to give instructions to computers to 
develop software, we need to learn a small amount about 
how computers are built.  If you were to take
apart your computer or cell phone and look deep
inside, you would find the following parts:

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/arch.eps}}
\afterfig

The high-level definitions of these parts are as follows:

\begin{itemize}

\item The {\bf Central Processing Unit} (or CPU) is 
that part of the computer that is built to be obsessed 
with ``what is next?''.  If your computer is rated
at 3.0 Gigahertz, it means that the CPU will ask ``What next?''
three billion times per second.  You are going to have to 
learn how to talk fast to keep up with the CPU.

\item The {\bf Main Memory} is used to store information
that the CPU needs in a hurry.  The main memory is nearly as 
fast as the CPU.  But the information stored in the main
memory vanishes when the computer is turned off.

\item The {\bf Secondary Memory} is also used to store
information, but it is much slower than the main memory.
The advantage of the secondary memory is that it can
store information even when there is no power to the
computer.  Examples of secondary memory are disk drives
or flash memory (typically found in USB sticks and portable
music players).

\item The {\bf Input and Output Devices} are simply our
screen, keyboard, mouse, microphone, speaker, touchpad, etc.  
They are all of the ways we interact with the computer.

\item These days, most computers also have a
{\bf Network Connection} to retrieve information over a network.
We can think of the network as a very slow place to store and
retrieve data that might not always be ``up''.  So in a sense,
the network is a slower and at times unreliable form of
{\bf Secondary Memory}

\end{itemize}

While most of the detail of how these components work is best left 
to computer builders, it helps to have some terminology
so we can talk about these different parts as we write our programs.

As a programmer, your job is to use and orchestrate 
each of these resources to solve the problem that you need solving
and analyze the data you need.  As a programmer you will 
mostly be ``talking'' to the CPU and telling it what to 
do next.  Sometimes you will tell the CPU to use the main memory,
secondary memory, network, or the input/output devices.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/arch2.eps}}
\afterfig

You need to be the person who answers the CPU's ``What next?'' 
question.  But it would be very uncomfortable to shrink you 
down to 5mm tall and insert you into the computer just so you 
could issue a command three billion times per second.  So instead,
you must write down your instructions in advance.
We call these stored instructions a {\bf program} and the act 
of writing these instructions down and getting the instructions to 
be correct {\bf programming}.

\section{Understanding programming}

In the rest of this book, we will try to turn you into a person
who is skilled in the art of programming.  In the end you will be a 
{\bf programmer} --- perhaps not a professional programmer but 
at least you will have the skills to look at a data/information
analysis problem and develop a program to solve the problem.

\index{problem solving}

In a sense, you need two skills to be a programmer:

\begin{itemize}

\item First you need to know the programming language (Python) -
you need to know the vocabulary and the grammar.  You need to be able 
spell the words in this new language properly and how to construct 
well-formed ``sentences'' in this new languages.

\item Second you need to ``tell a story''.  In writing a story,
you combine words and sentences to convey an idea to the reader. 
There is a skill and art in constructing the story and skill in
story writing is improved by doing some writing and getting some
feedback.  In programming, our program is the ``story'' and the 
problem you are trying to solve is the ``idea''.

\end{itemize}

Once you learn one programming language such as Python, you will 
find it much easier to learn a second programming language such
as JavaScript or C++.  The new programming language has very different 
vocabulary and grammar but once you learn problem solving skills, 
they will be the same across all programming languages.

You will learn the ``vocabulary'' and ``sentences'' of Python pretty quickly.
It will take longer for you to be able to write a coherent program
to solve a brand new problem.  We teach programming much like we teach
writing.  We start reading and explaining programs and then we write 
simple programs and then write increasingly complex programs over time.
At some point you ``get your muse'' and see the patterns on your own
and can see more naturally how to take a problem and 
write a program that solves that problem.  And once you get 
to that point, programming becomes a very pleasant and creative process.  

We start with the vocabulary and structure of Python programs.  Be patient
as the simple examples remind you of when you started reading for the first
time. 

\section{Words and sentences}
\index{programming language}
\index{language!programming}

Unlike human languages, the Python vocabulary is actually pretty small.
We call this ``vocabulary'' the ``reserved words''.  These are words that
have very special meaning to Python.  When Python sees these words in 
a Python program, they have one and only one meaning to Python.  Later
as you write programs you will make your own words that have meaning to 
you called {\bf variables}.   You will have great latitude in choosing
your names for your variables, but you cannot use any of Python's 
reserved words as a name for a variable.

In a sense, when we train a dog, we would use special words like,
``sit'', ``stay'', and ``fetch''.  Also when you talk to a dog and
don't use any of the reserved words, they just look at you with a 
quizzical look on their faces until you say a reserved word.  
For example, if you say, 
``I wish more people would walk to improve their overall health.'', 
what most dogs likely hear is,
``blah blah blah {\bf walk} blah blah blah blah.''
That is because ``walk'' is a reserved word in dog language.  Many
might suggest that the language between humans and cats has no
reserved words\footnote{\url{http://xkcd.com/231/}}.

The reserved words in the language where humans talk to 
Python incudes the following:

\beforeverb
\begin{verbatim}
and       del       from      not       while    
as        elif      global    or        with     
assert    else      if        pass      yield    
break     except    import    print              
class     exec      in        raise              
continue  finally   is        return             
def       for       lambda    try
\end{verbatim}
\afterverb
%
That is it, and unlike a dog, Python is already completely trained.
When you say ``try'', Python will try every time you say it without
fail.

We will learn these reserved words and how they are used in good time,
but for now we will focus on the Python equivalent of ``speak'' (in 
human to dog language).  The nice thing about telling Python to speak
is that we can even tell it what to say by giving it a message in quotes:

\beforeverb
\begin{verbatim}
print 'Hello world!'
\end{verbatim}
\afterverb

And we have even written our first syntactically correct Python sentence.
Our sentence starts with the reserved word {\bf print} followed
by a string of text of our choosing enclosed in single quotes.

\section{Conversing with Python}

Now that we have a word and a simple sentence that we know in Python,
we need to know how to start a conversation with Python to test 
our new language skills.

Before you can converse with Python, you must first install the Python
software on your computer and learn how to start Python on your 
computer.  That is too much detail for this chapter so I suggest
that you consult \url{www.pythonlearn.com} where I have detailed
instructions and screencasts of setting up and starting Python 
on Macintosh and Windows systems.  At some point, you will be in 
a terminal or command window and you will type {\bf python} and 
the Python interpreter will start executing in interactive mode
and appear somewhat as follows:
\index{interactive mode}

\beforeverb
\begin{verbatim}
Python 2.6.1 (r261:67515, Jun 24 2010, 21:47:49) 
[GCC 4.2.1 (Apple Inc. build 5646)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> 
\end{verbatim}
\afterverb
%
The {\tt >>>} prompt is the Python interpreter's way of asking you, ``What
do you want me to do next?''.  Python is ready to have a conversation with
you.  All you have to know is how to speak the Python language and you 
can have a conversation.

Lets say for example that you did not know even the simplest Python language
words or sentences. You might want to use the standard line that astronauts 
use when they land on a far away planet and try to speak with the inhabitants
of the planet:

\beforeverb
\begin{verbatim}
>>> I come in peace, please take me to your leader
  File "<stdin>", line 1
    I come in peace, please take me to your leader
         ^
SyntaxError: invalid syntax
>>> 
\end{verbatim}
\afterverb
%
This is not going so well.  Unless you think of something quickly,
the inhabitants of the planet are likely to stab you with their spears, 
put you on a spit, roast you over a fire, and eat you for dinner.

Luckily you brought a copy of this book on your travels and you thumb to
this very page and try again:

\beforeverb
\begin{verbatim}
>>> print 'Hello world!'
Hello world!
\end{verbatim}
\afterverb
%
This is looking much better so you try to communicate some
more:

\beforeverb
\begin{verbatim}
>>> print 'You must be the legendary god that comes from the sky'
You must be the legendary god that comes from the sky
>>> print 'We have been waiting for you for a long time'
We have been waiting for you for a long time
>>> print 'Our legend says you will be very tasty with mustard'
Our legend says you will be very tasty with mustard
>>> print 'We will have a feast tonight unless you say
  File "<stdin>", line 1
    print 'We will have a feast tonight unless you say
                                                     ^
SyntaxError: EOL while scanning string literal
>>> 
\end{verbatim}
\afterverb
%
The conversation was going so well for a while and then you
made the tiniest mistake using the Python language and Python 
brought the spears back out.

At this point, you should also realize that while Python 
is amazingly complex and powerful and very picky about 
the syntax you use to communicate with it, Python is {\em 
not} intelligent.  You are having a conversation with 
yourself but using proper syntax.

In a sense when you use a program written by someone else
the conversation is between you and those other
programmers with Python acting as an intermediary.  Python
is a way for the creators of programs to express how the 
conversation is supposed to proceed.  And
in just a few more chapters, you will be one of those
programmers using Python to talk to the users of your program.

Before we leave our first conversation with the Python 
interpreter, you should probably know the proper way
to say ``good-bye'' when interacting with the inhabitants
of Planet Python:

\beforeverb
\begin{verbatim}
>>> good-bye
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'good' is not defined

>>> if you don't mind, I need to leave
  File "<stdin>", line 1
    if you don't mind, I need to leave
             ^
SyntaxError: invalid syntax

>>> quit()
\end{verbatim}
\afterverb
%
You will notice that the error is different for the first two
incorrect attempts.   The second error is different because 
{\bf if} is a reserved word and Python saw the reserved word
and thought we were trying to say something but got the syntax
of the sentence wrong.

The proper way to say ``good-bye'' to Python is to enter 
{\bf quit()} at the interactive chevron {\tt >>>} prompt.
It would have probably taken you quite a while to guess that 
one so having a book handy probably will turn out 
to be helpful.

\section{Terminology: interpreter and compiler}

Python is a {\bf high-level} language intended to be relatively
straightforward for humans to read and write and for computers
to read and process.  Other high-level languages include: Java, C++,
PHP, Ruby, Basic, Perl, JavaScript, and many more.  The actual hardware
inside the Central Processing Unit (CPU) does not understand any
of these high level languages.

The CPU understands a language we call {\bf machine-language}.  Machine
language is very simple and frankly very tiresome to write because it 
is represented all in zeros and ones:

\beforeverb
\begin{verbatim}
01010001110100100101010000001111
11100110000011101010010101101101
...
\end{verbatim}
\afterverb
%
Machine language seems quite simple on the surface given that there 
are only zeros and ones, but its syntax is even more complex
and far more intricate than Python.  So very few programmers ever write
machine language.  Instead we build various translators to allow
programmers to write in high level languages like Python or JavaScript
and these translators convert the programs to machine language for actual
execution by the CPU.

Since machine language is tied to the computer hardware, machine language
is not {\bf portable} across different types of hardware.  Programs written in 
high-level languages can be moved between different computers by using a 
different interpreter on the new machine or re-compiling the code to create
a machine language version of the program for the new machine.

These programming language translators fall into two general categories:
(1) interpreters and (2) compilers.

An {\bf interpreter} reads the source code of the program as written by the
programmer, parses the source code, and interprets the instructions on-the-fly.
Python is an interpreter and when we are running Python interactively, 
we can type a line of Python (a sentence) and Python processes it immediately
and is ready for us to type another line of Python.   

Some of the lines of Python tell Python that you want it to remember some 
value for later.   We need to pick a name for that value to be remembered and
we can use that symbolic name to retrieve the value later.  We use the 
term {\bf variable} to refer to the labels we use to refer to this stored data.

\beforeverb
\begin{verbatim}
>>> x = 6
>>> print x
6
>>> y = x * 7
>>> print y
42
>>> 
\end{verbatim}
\afterverb
%
In this example, we ask Python to remember the value six and use the label {\bf x}
so we can retrieve the value later.   We verify that Python has actually remembered
the value using {\bf print}. Then we ask Python to retrieve {\bf x} and multiply
it by seven and put the newly-computed value in {\bf y}.  Then we ask Python to print out
the value currently in {\bf y}.

Even though we are typing these commands into Python one line at a time, Python
is treating them as an ordered sequence of statements with later statements able
to retrieve data created in earlier statements.   We are writing our first 
simple paragraph with four sentences in a logical and meaningful order.

It is the nature of an {\bf interpreter} to be able to have an interactive conversation
as shown above.  A {\bf compiler} needs to be handed the entire program in a file, and then 
it runs a process to translate the high level source code into machine language
and then the compiler puts the resulting machine language into a file for later
execution.

If you have a Windows system, often these executable machine language programs have a
suffix of ``.exe'' or ``.dll'' which stand for ``executable'' and ``dynamically loadable
library'' respectively.  In Linux and Macintosh there is no suffix that uniquely marks
a file as executable.

If you were to open an executable file in a text editor, it would look 
completely crazy and be unreadable:

\beforeverb
\begin{verbatim}
^?ELF^A^A^A^@^@^@^@^@^@^@^@^@^B^@^C^@^A^@^@^@\xa0\x82
^D^H4^@^@^@\x90^]^@^@^@^@^@^@4^@ ^@^G^@(^@$^@!^@^F^@
^@^@4^@^@^@4\x80^D^H4\x80^D^H\xe0^@^@^@\xe0^@^@^@^E
^@^@^@^D^@^@^@^C^@^@^@^T^A^@^@^T\x81^D^H^T\x81^D^H^S
^@^@^@^S^@^@^@^D^@^@^@^A^@^@^@^A\^D^HQVhT\x83^D^H\xe8
....
\end{verbatim}
\afterverb
%
It is not easy to read or write machine language so it is nice that we have
{\bf interpreters} and {\bf compilers} that allow us to write in a high-level
language like Python or C.

Now at this point in our discussion of compilers and interpreters, you should 
be wondering a bit about the Python interpreter itself.  What language is 
it written in?  Is it written in a compiled language?  When we type
``python'', what exactly is happening?

The Python interpreter is written in a high level language called ``C''.  
You can look at the actual source code for the Python interpreter by
going to \url{www.python.org} and working your way to their source code.
So Python is a program itself and it is compiled into machine code and
when you installed Python on your computer (or the vendor installed it),
you copied a machine-code copy of the translated Python program onto your
system.   In Windows the executable machine code for Python itself is likely
in a file with a name like:

\beforeverb
\begin{verbatim}
C:\Python27\python.exe
\end{verbatim}
\afterverb
%
That is more than you really need to know to be a Python programmer, but
sometimes it pays to answer those little nagging questions right at 
the beginning.

\section{Writing a program}

Typing commands into the Python interpreter is a great way to experiment 
with Python's features, but it is not recommended for solving more complex problems.

When we want to write a program, 
we use a text editor to write the Python instructions into a file,
which is called a {\bf script}.  By
convention, Python scripts have names that end with {\tt .py}.

\index{script}

To execute the script, you have to tell the Python interpreter 
the name of the file.  In a Unix or Windows command window, 
you would type {\tt python hello.py} as follows:

\beforeverb
\begin{verbatim}
csev$ cat hello.py
print 'Hello world!'
csev$ python hello.py
Hello world!
csev$
\end{verbatim}
\afterverb
%
The ``csev\$'' is the operating system prompt, and the ``cat hello.py'' is 
showing us that the file ``hello.py'' has a one line Python program to print
a string.

We call the Python interpreter and tell it to read its source code from
the file ``hello.py'' instead of prompting us for lines of Python code
interactively.

You will notice that there was no need to have {\bf quit()} at the end of
the Python program in the file.   When Python is reading your source code
form a file, it knows to stop when it reaches the end of the file.

\section{What is a program?}

The definition of a {\bf program} at its most basic is a sequence
of Python statements that have been crafted to do something.
Even our simple {\bf hello.py} script is a program.  It is a one-line
program and is not particularly useful, but in the strictest definition,
it is a Python program.

It might be easiest to understand what a program is by thinking about a problem 
that a program might be built to solve, and then looking at a program
that would solve that problem.

Lets say you are doing Social Computing research on Facebook posts and 
you are interested in the most frequently used word in a series of posts.
You could print out the stream of facebook posts and pore over the text
looking for the most common word, but that would take a long time and be very 
mistake prone.  You would be smart to write a Python program to handle the
task quickly and accurately so you can spend the weekend doing something 
fun.

For example look at the following text about a clown and a car.  Look at the 
text and figure out the most common word and how many times it occurs.

\beforeverb
\begin{verbatim}
the clown ran after the car and the car ran into the tent 
and the tent fell down on the clown and the car 
\end{verbatim}
\afterverb
%
Then imagine that you are doing this task looking at millions of lines of 
text.  Frankly it would be quicker for you to learn Python and write a 
Python program to count the words than it would be to manually 
scan the words.

The even better news is that I already came up with a simple program to 
find the most common word in a text file.  I wrote it,
tested it, and now I am giving it to you to use so you can save some time.

\beforeverb
\begin{verbatim}
name = raw_input('Enter file:')
handle = open(name, 'r')
text = handle.read()
words = text.split()
counts = dict()

for word in words:
   counts[word] = counts.get(word,0) + 1

bigcount = None
bigword = None
for word,count in counts.items():
    if bigcount is None or count > bigcount:
        bigword = word
        bigcount = count

print bigword, bigcount
\end{verbatim}
\afterverb
%
You don't even need to know Python to use this program.  You will need to get through 
Chapter 10 of this book to fully understand the awesome Python techniques that were
used to make the program.  You are the end user, you simply use the program and marvel
at its cleverness and how it saved you so much manual effort.
You simply type the code 
into a file called {\bf words.py} and run it or you download the source 
code from \url{http://www.pythonlearn.com/code/} and run it.

\index{program}
This is a good example of how Python and the Python language are acting as an intermediary
between you (the end-user) and me (the programmer).  Python is a way for us to exchange useful
instruction sequences (i.e. programs) in a common language that can be used by anyone who 
installs Python on their computer.  So neither of us are talking {\em to Python},
instead we are communicating with each other {\em through} Python.

\section{The building blocks of programs}

In the next few chapters, we will learn more about the vocabulary, sentence structure,
paragraph structure, and story structure of Python.  We will learn about the powerful
capabilities of Python and how to compose those capabilities together to create useful
programs.

There are some low-level conceptual patterns that we use to construct programs.  These
constructs are not just for Python programs, they are part of every programming language
from machine language up to the high-level languages.

\begin{description}

\item[input:] Get data from the ``outside world''.  This might be 
reading data from a file, or even some kind of sensor like 
a microphone or GPS.  In our initial programs, our input will come from the user
typing data on the keyboard.

\item[output:] Display the results of the program on a screen
or store them in a file or perhaps write them to a device like a
speaker to play music or speak text.

\item[sequential execution:] Perform statements one after
another in the order they are encountered in the script.

\item[conditional execution:] Check for certain conditions and
execute or skip a sequence of statements.

\item[repeated execution:] Perform some set of statements 
repeatedly, usually with
some variation.

\item[reuse:] Write a set of instructions once and give them a name
and then reuse those instructions as needed throughout your program.

\end{description}

It sounds almost too simple to be true and of course it is never
so simple.  It is like saying that walking is simply
``putting one foot in front of the other''.  The ``art'' 
of writing a program is composing and weaving these
basic elements together many times over to produce something
that is useful to its users.

The word counting program above directly uses all of 
these patterns except for one.

\section{What could possibly go wrong?}

As we saw in our earliest conversations with Python, we must
communicate very precisely when we write Python code.  The smallest
deviation or mistake will cause Python to give up looking at your
program.

Beginning programmers often take the fact that Python leaves no
room for errors as evidence that Python is mean, hateful and cruel.
While Python seems to like everyone else, Python knows them 
personally and holds a grudge against them.  Because of this grudge,
Python takes our perfectly written programs and rejects them as 
``unfit'' just to torment us.

\beforeverb
\begin{verbatim}
>>> primt 'Hello world!'
  File "<stdin>", line 1
    primt 'Hello world!'
                       ^
SyntaxError: invalid syntax
>>> primt 'Hello world'
  File "<stdin>", line 1
    primt 'Hello world'
                      ^
SyntaxError: invalid syntax
>>> I hate you Python!
  File "<stdin>", line 1
    I hate you Python!
         ^
SyntaxError: invalid syntax
>>> if you come out of there, I would teach you a lesson
  File "<stdin>", line 1
    if you come out of there, I would teach you a lesson
              ^
SyntaxError: invalid syntax
>>> 
\end{verbatim}
\afterverb
%
There is little to be gained by arguing with Python.  It is a tool,
it has no emotion and it is happy and ready to serve you whenever you
need it.  Its error messages sound harsh, but they are just Python's
call for help.  It has looked at what you typed, and it simply cannot
understand what you have entered.

Python is much more like a dog, loving you unconditionally, having a few
key words that it understands, looking you with a sweet look on its
face ({\tt >>>}) and waiting for you to say something it understands.
When Python says ``SyntaxError: invalid syntax'', it is simply wagging
its tail and saying, ``You seemed to say something but I just don't
understand what you meant, but please keep talking to me ({\tt >>>}).''

As your programs become increasingly sophisticated, you will encounter three 
general types of errors:

\begin{description}

\item[Syntax errors:] These are the first errors you will make and the easiest
to fix.  A syntax error means that you have violated the ``grammar'' rules of Python.
Python does its best to point right at the line and character where 
it noticed it was confused.  The only tricky bit of syntax errors is that sometimes
the mistake that needs fixing is actually earlier in the program than where Python
{\em noticed} it was confused.  So the line and character that Python indicates in 
a syntax error may just be a starting point for your investigation.

\item[Logic errors:] A logic error is when your program has good syntax but there is a mistake 
in the order of the statements or perhaps a mistake in how the statements relate to one another.
A good example of a logic error might be, ``take a drink from your water bottle, put it 
in your backpack, walk to the library, and then put the top back on the bottle.''

\item[Semantic errors:] A semantic error is when your description of the steps to take 
is syntactically perfect and in the right order, but there is simply a mistake in 
the program.  The program is perfectly correct but it does not do what
you {\em intended} for it to do. A simple example would
be if you were giving a person directions to a restaurant and said, ``... when you reach
the intersection with the gas station, turn left and go one mile and the restaurant
is a red building on your left.''.  Your friend is very late and calls you to tell you that
they are on a farm and walking around behind a barn, with no sign of a restaurant.  
Then you say ``did you turn left or right at the gas station?'' and 
they say, ``I followed your directions perfectly, I have 
them written down, it says turn left and go one mile at the gas station.''.  Then you say,
``I am very sorry, because while my instructions were syntactically correct, they 
sadly contained a small but undetected semantic error.''. 

\end{description}

Again in all three types of errors, Python is merely trying its hardest to 
do exactly what you have asked.

\section{The learning journey}

As you progress through the rest of the book, don't be afraid if the concepts 
don't seem to fit together well the first time.  When you were learning to speak, 
it was not a problem  for your first few years that you just made cute gurgling noises.
And it was OK if it took six months for you to move from simple vocabulary to 
simple sentences and took 5-6 more years to move from sentences to paragraphs, and a
few more years to be able to write an interesting complete short story on your own.

We want you to learn Python much more rapidly, so we teach it all at the same time
over the next few chapters.  
But it is like learning a new language that takes time to absorb and understand
before it feels natural.
That leads to some confusion as we visit and revisit
topics to try to get you to see the big picture while we are defining the tiny
fragments that make up the big picture.  While the book is written linearly and
if you are taking a course, it will progress in a linear fashion, don't hesitate
to be very non-linear in how you approach the material.  Look forwards and backwards
and read with a light touch.  By skimming more advanced material without 
fully understanding the details, you can get a better understanding of the ``why?'' 
of programming.  By reviewing previous material and even re-doing earlier 
exercises, you will realize that you actually learned a lot of material even 
if the material you are currently staring at seems a bit impenetrable.

Usually when you are learning your first programming language, there are a few
wonderful ``Ah-Hah!'' moments where you can look up from pounding away at some rock
with a hammer and chisel and step away and see that you are indeed building 
a beautiful sculpture.

If something seems particularly hard, there is usually no value in staying up all 
night and staring at it.   Take a break, take a nap, have a snack, explain what you 
are having a problem with to someone (or perhaps your dog), and then come back to it with
fresh eyes.  I assure you that once you learn the programming concepts in the book
you will look back and see that it was all really easy and elegant and it simply 
took you a bit of time to absorb it.

\section{Glossary}

\begin{description}

\item[bug:]  An error in a program.
\index{bug}

\item[central processing unit:] The heart of any computer.  It is what
runs the software that we write; also called ``CPU'' or ``the processor''.
\index{central processing unit}
\index{CPU}

\item[compile:]  To translate a program written in a high-level language
into a low-level language all at once, in preparation for later
execution.
\index{compile}

\item[high-level language:]  A programming language like Python that
is designed to be easy for humans to read and write.
\index{high-level language}

\item[interactive mode:] A way of using the Python interpreter by
typing commands and expressions at the prompt.
\index{interactive mode}

\item[interpret:]  To execute a program in a high-level language
by translating it one line at a time.
\index{interpret}

\item[low-level language:]  A programming language that is designed
to be easy for a computer to execute; also called ``machine code'' or
``assembly language.''
\index{low-level language}

\item[machine code:]  The lowest level language for software which 
is the language that is directly executed by the central processing unit 
(CPU).
\index{machine code}

\item[main memory:] Stores programs and data.  Main memory loses 
its information when the power is turned off.
\index{main memory}

\item[parse:]  To examine a program and analyze the syntactic structure.
\index{parse}

\item[portability:]  A property of a program that can run on more
than one kind of computer.
\index{portability}

\item[print statement:]  An instruction that causes the Python
interpreter to display a value on the screen.
\index{print statement}
\index{statement!print}

\item[problem solving:]  The process of formulating a problem, finding
a solution, and expressing the solution.
\index{problem solving}

\item[program:] A set of instructions that specifies a computation.
\index{program}

\item[prompt:] When a program displays a message and pauses for the 
user to type some input to the program.
\index{prompt}

\item[secondary memory:] Stores programs and data and retains its 
information even when the power is turned off.  Generally slower 
than main memory.  Examples of secondary memory include disk 
drives and flash memory in USB sticks.
\index{secondary memory}

\item[semantics:]  The meaning of a program.
\index{semantics}

\item[semantic error:]   An error in a program that makes it do something
other than what the programmer intended.
\index{semantic error}

\item[source code:]  A program in a high-level language.
\index{source code}

\end{description}

\section{Exercises}


\begin{ex}
What is the function of the secondary memory in a computer?

a) Execute all of the computation and logic of the program\\
b) Retrieve web pages over the Internet\\
c) Store information for the long term - even beyond a power cycle\\
d) Take input from the user 
\end{ex}

\begin{ex}
What is a program?
\end{ex}

\begin{ex}
What is the difference between a compiler and an interpreter?
\end{ex}

\begin{ex}
Which of the following contains "machine code"?

a) The Python interpreter\\
b) The keyboard\\
c) Python source file\\
d) A word processing document
\end{ex}

\begin{ex}
What is wrong with the following code:

\beforeverb
\begin{verbatim}
>>> primt 'Hello world!'
  File "<stdin>", line 1
    primt 'Hello world!'
                       ^
SyntaxError: invalid syntax
>>> 
\end{verbatim}
\afterverb

\end{ex}

\begin{ex}
Where in the computer is a variable such as "X" stored 
after the following Python line finishes?

\beforeverb
\begin{verbatim}
x = 123
\end{verbatim}
\afterverb
%
a) Central processing unit\\
b) Main Memory\\
c) Secondary Memory\\
d) Input Devices\\
e) Output Devices
\end{ex}

\begin{ex}
What will the following program print out:

\beforeverb
\begin{verbatim}
x = 43
x = x + 1
print x
\end{verbatim}
\afterverb
%
a) 43\\
b) 44\\
c) x + 1\\
d) Error because x = x + 1 is not possible mathematically
\end{ex}

\begin{ex}
Explain each of the following using an example of a human capability: 
(1) Central processing unit, (2) Main Memory, (3) Secondary Memory, 
(4) Input Device, and
(5) Output Device.
For example, "What is the human equivalent to a Central Processing Unit"? 
\end{ex}

\begin{ex}
How do you fix a "Syntax Error"?
\end{ex}

\input{book.tex}

\chapter{Regular expressions}

So far we have been reading through files, looking for patterns and extracting various bits of lines that we find interesting.  We have been using string methods like {\tt split} and {\tt find} and using lists and string slicing to extract portions of the lines.
\index{regular expressions}
\index{regex}
\index{re module}

This task of searching and extracting is so common that Python has a very powerful library called {\bf regular expressions} that handles many of these tasks quite elegantly.  The reason we have not introduced regular expressions earlier in the book is because while they are very powerful, they are a little complicated and their syntax takes some getting used to. 

Regular expressions are almost their own little programming language for searching and parsing strings.  As a matter of fact, entire books have been written on the topic of regular expressions.  In this chapter, we will only cover the basics of regular expressions.  For more detail on regular expressions, see:

\url{http://en.wikipedia.org/wiki/Regular_expression}

\url{http://docs.python.org/library/re.html}

The regular expression library must be imported into your program before you can use it.  The simplest use of the regular expression library is the {\tt search()} function.  The following program demonstrates a trivial use of the search function.
\index{regex!search}

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('From:', line) :
        print line
\end{verbatim}
\afterverb
%
We open the file, loop through each line and use the regular expression {\tt search()} to only print out lines that contain the string ``From:''.   This program does not use the real power of regular expressions since we could have just as easily used {\tt line.find()} to accomplish the same result.
\index{string!find}

The power of the regular expressions comes when we add to special characters to the search string that allow us to more precisely control which lines match the string.  Adding these special characters to our regular expression allow us to do sophisticated matching and extraction while writing very little code.

For example, the caret character is uses in regular 
expressions to match ``the beginning'' of a line.
We could change our application to only match 
lines where ``From:'' was at the beginning of the line as follows:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('^From:', line) :
        print line
\end{verbatim}
\afterverb
%
Now we will only match lines that {\em start with} the string ``From:''.  This is still a very simple example that we could have done equivalently with the {\tt startswith()} method from the string library.  But it serves to introduce the notion that regular expressions contain special action characters that give us more control as to what will match the regular expression.
\index{string!startswith}

\section{Character matching in regular expressions}

There are a number of other special characters that let us build even more powerful regular expressions.  The most commonly used special character is the period character which matches any character.
\index{wild card}
\index{regex!wild card}

In the following example, the regular expression ``F..m:'' would match any of the strings ``From:'', ``Fxxm:'', ``F12m:'', or ``F!@m:'' since the period characters in the regular expression match any character.

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('^F..m:', line) :
        print line
\end{verbatim}
\afterverb
%
This is particularly powerful when combined with the ability to indicate that a character can be repeated any number of times using the ``*'' or ``+'' characters in your regular expression.   These special characters mean that instead of matching a single character in the search string they match zero-or-more in the case of the asterisk or one-or-more of the characters in the case of the plus sign.

We can further narrow down the lines that we match using a repeated {\bf wild card} character in the following example:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('^From:.+@', line) :
        print line
\end{verbatim}
\afterverb
%
The search string ``\verb"^"From:.+@'' will successfully match lines that start with ``From:'' followed by one or more characters ``.+'' followed by an at-sign.  So this will match the following line:

\beforeverb
\begin{alltt}
{\bf From:}\underline{ stephen.marquard}{\bf @}uct.ac.za
\end{alltt}
\afterverb

You can think of the ``.+'' wildcard as expanding to match all the characters between the 
colon character and the at-sign.  

\beforeverb
\begin{alltt}
{\bf From:}\underline{.+}{\bf @}
\end{alltt}
\afterverb

It is good to think of the plus and asterisk characters as ``pushy''.  For example the following string would match the last at-sign in the string as the ``.+'' pushes outwards as shown below:

\beforeverb
\begin{alltt}
{\bf From:}\underline{ stephen.marquard@uct.ac.za, csev@umich.edu, and cwen}{\bf @}iupui.edu
\end{alltt}
\afterverb

It is possible to tell an asterisk or plus-sign not to be so ``greedy'' by adding 
another character.   See the detailed documentation for information on turning off the 
greedy behavior.
\index{greedy}

\section{Extracting data using regular expressions}

If we want to extract data from a string in Python we can use the {\tt findall()} method to extract all of the substrings which match a regular expression.  Let's use the example of wanting to extract anything that looks like an e-mail address from any line regardless of format.  For example, we want to pull the e-mail addresses from each of the following lines:

\beforeverb
\begin{verbatim}
From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008
Return-Path: <postmaster@collab.sakaiproject.org>
          for <source@collab.sakaiproject.org>;
Received: (from apache@localhost)
Author: stephen.marquard@uct.ac.za
\end{verbatim}
\afterverb
%
We don't want to write code for each of the types of lines, splitting and slicing differently for each line.  This following program uses {\tt findall()} to find the lines with e-mail addresses in them and extract one or more addresses from each of those lines.
\index{findall}
\index{regex!findall}

\beforeverb
\begin{verbatim}
import re
s = 'Hello from csev@umich.edu to cwen@iupui.edu about the meeting @2PM'
lst = re.findall('\S+@\S+', s)
print lst
\end{verbatim}
\afterverb
%
The {\tt findall()} method searches the string in the second argument and returns a list of all of the strings that look like e-mail addresses.   We are using a two-character sequence 
that matches a non-whitespace character ({\textbackslash}S). 

The output of the program would be:

\beforeverb
\begin{verbatim}
['csev@umich.edu', 'cwen@iupui.edu']
\end{verbatim}
\afterverb
%
Translating the regular expression, we are looking for substrings that have at least one non-whitespace character, followed by an at-sign, followed by at least one more non-white space characters.  Also, the ``{\textbackslash}S+'' matches as many non-whitespace characters as possible (this is called {\bf ``greedy''} matching in regular expressions).  

The regular expression would match twice (csev@umich.edu and cwen@iupui.edu) but it would not match the string ``@2PM'' because there are no non-blank characters {\em before} the at-sign.  
We can use this regular expression in a program to read all the lines in a file and print out anything that looks like an e-mail address as follows:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    x = re.findall('\S+@\S+', line)
    if len(x) > 0 :
        print x
\end{verbatim}
\afterverb
%
We read each line and then extract all the substrings that match our regular expression.  Since {\tt findall()} returns a list, we simple check if the number of elements in our returned list is more than zero to print only lines where we found at least one substring that looks like an e-mail address.

If we run the program on {\tt mbox.txt} we get the following output:

\beforeverb
\begin{verbatim}
['wagnermr@iupui.edu']
['cwen@iupui.edu']
['<postmaster@collab.sakaiproject.org>']
['<200801032122.m03LMFo4005148@nakamura.uits.iupui.edu>']
['<source@collab.sakaiproject.org>;']
['<source@collab.sakaiproject.org>;']
['<source@collab.sakaiproject.org>;']
['apache@localhost)']
['source@collab.sakaiproject.org;']
\end{verbatim}
\afterverb
%
Some of our E-mail addresses have incorrect characters like ``\verb"<"'' or ``;'' at the beginning or end.   Let's declare that we are only interested in the portion of the string that starts and ends with a letter or a number.

To do this, we use another feature of regular expressions.  Square brackets are used to indicate a set of multiple acceptable characters we are willing to consider matching.  In a sense, the ``{\textbackslash}S'' is asking to match the set of ``non-whitespace characters''.  Now we will be a little more explicit in terms of the characters we will match.

Here is our new regular expression:

\beforeverb
\begin{verbatim}
[a-zA-Z0-9]\S*@\S*[a-zA-Z]
\end{verbatim}
\afterverb
%
This is getting a little complicated and you can begin to see why regular expressions are their own little language unto themselves.  Translating this regular expression, we are looking for substrings that start with a {\em single} lowercase letter, upper case letter, or number ``[a-zA-Z0-9]'' followed by zero or more non blank characters ``{\textbackslash}S*'', followed by an at-sign, followed by zero or more non-blank characters ``{\textbackslash}S*'' followed by an upper or lower case letter.  Note that we switched from ``+'' to ``*'' to indicate zero-or-more non-blank characters since ``[a-zA-Z0-9]'' is already one non-blank character.   Remember that the ``*'' or ``+'' applies to the single character immediately to the left of the plus or asterisk.
\index{regex!character sets(brackets)}

If we use this expression in our program, our data is much cleaner:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    x = re.findall('[a-zA-Z0-9]\S*@\S*[a-zA-Z]', line)
    if len(x) > 0 :
        print x
\end{verbatim}
\afterverb
%

\beforeverb
\begin{verbatim}
...
['wagnermr@iupui.edu']
['cwen@iupui.edu']
['postmaster@collab.sakaiproject.org']
['200801032122.m03LMFo4005148@nakamura.uits.iupui.edu']
['source@collab.sakaiproject.org']
['source@collab.sakaiproject.org']
['source@collab.sakaiproject.org']
['apache@localhost']
\end{verbatim}
\afterverb
%
Notice that on the ``source@collab.sakaiproject.org'' lines, our regular expression eliminated two letters at the end of the string (``\verb">";'').  This is because when we append ``[a-zA-Z]'' to the end of our regular expression, we are demanding that whatever string the regular expression parser finds, it must end with a letter.   So when it sees the ``\verb">"'' after ``sakaiproject.org\verb">";'' it simply stops at the last ``matching'' letter it found (i.e. the ``g'' was the last good match).

Also note that the output of the program is a Python list that has a string as the single element in the list.

\section{Combining searching and extracting}

If we want to find numbers on lines that start with the string ``X-'' such as:

\beforeverb
\begin{verbatim}
X-DSPAM-Confidence: 0.8475
X-DSPAM-Probability: 0.0000  
\end{verbatim}
\afterverb
%
We don't just want any floating point numbers from any lines.  We only to extract numbers from lines that have the above syntax.

We can construct the following regular expression to select the lines:

\beforeverb
\begin{verbatim}
^X-.*: [0-9.]+
\end{verbatim}
\afterverb
%
Translating this, we are saying, we want lines that start with ``X-'' followed by zero or more characters ``.*'' followed by a colon (``:'') and then a space.  After the space we are looking for one or more characters that are either a digit (0-9) or a period ``[0-9.]+''.  Note that in between the square braces, the period matches an actual period (i.e. it is not a wildcard between the square brackets).

This is a very tight expression that will pretty much match only the lines we are interested in as follows:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    if re.search('^X\S*: [0-9.]+', line) :
        print line
\end{verbatim}
\afterverb
%
When we run the program, we see the data nicely filtered to show 
only the lines we are looking for.

\beforeverb
\begin{verbatim}
X-DSPAM-Confidence: 0.8475
X-DSPAM-Probability: 0.0000
X-DSPAM-Confidence: 0.6178
X-DSPAM-Probability: 0.0000
\end{verbatim}
\afterverb
%
But now we have to solve the problem of extracting the numbers using {\tt split}.  While it would be simple enough to use {\tt split}, we can use another feature of regular expressions to both search and parse the line at the same time.
\index{string!split}

Parentheses are another special character in regular expressions.  When you add parentheses to a regular expression they are ignored when matching the string, but when you are using {\tt findall()}, parentheses indicate that while you want the whole expression to match, you only are interested in extracting a portion of the substring that matches the regular expression.  
\index{regex!parentheses}
\index{parentheses!regular expression}

So we make the following change to our program:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    x = re.findall('^X\S*: ([0-9.]+)', line)
    if len(x) > 0 :
        print x
\end{verbatim}
\afterverb
%
Instead of calling {\tt search()}, we add parentheses around the part of the regular expression that represents the floating point number to indicate we only want {\tt findall()} to give us back the floating point number portion of the matching string.

The output from this program is as follows:

\beforeverb
\begin{verbatim}
['0.8475']
['0.0000']
['0.6178']
['0.0000']
['0.6961']
['0.0000']
..
\end{verbatim}
\afterverb
%
The numbers are still in a list and need to be converted from strings to floating point but we have used the power of regular expressions to both search and extract the information we found interesting.

As another example of this technique, if 
you look at the file there are a number of lines of the form:

\beforeverb
\begin{verbatim}
Details: http://source.sakaiproject.org/viewsvn/?view=rev&rev=39772
\end{verbatim}
\afterverb
%
If we wanted to extract all of the revision numbers (the integer number at the end of these lines) using the same technique as above,  we could write the following program:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    x = re.findall('^Details:.*rev=([0-9.]+)', line)
    if len(x) > 0:
        print x
\end{verbatim}
\afterverb
%
Translating our regular expression, we are looking for lines that start with ``Details:', followed by any number of characters ``.*'' followed by ``rev='' and then by one or more digits.   We want lines that match the entire expression but we only want to extract the integer number at the end of the line so we surround ``[0-9]+'' with parentheses.  

When we run the program, we get the following output:

\beforeverb
\begin{verbatim}
['39772']
['39771']
['39770']
['39769']
...
\end{verbatim}
\afterverb
%
Remember that the ``[0-9]+'' is ``greedy'' and it tries to make as large a string of digits as possible before extracting those digits.  This ``greedy'' behavior is why we get all five digits for each number.  The regular expression library expands in both directions until it counters a non-digit, the beginning, or the end of a line.

Now we can use regular expressions to re-do an exercise from earlier in the book where we were interested in the time of day of each mail message.   We looked for lines of the form:

\beforeverb
\begin{verbatim}
From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008
\end{verbatim}
\afterverb
%
And wanted to extract the hour of the day for each line.  Previously we did this with two calls to {\tt split}.  First the line was split into words and then we pulled out the fifth word and split it again on the colon character to pull out the two characters we were interested in.

% Add a section on the notion of brittle code
While this worked, it actually results in pretty brittle code that is assuming the lines are nicely formatted.  If you were to add enough error checking (or a big try/except block) to insure that your program never failed when presented with incorrectly formatted lines, the code would balloon to 10-15 lines of code that was pretty hard to read.

We can do this far simpler with the following regular expression:

\beforeverb
\begin{verbatim}
^From .* [0-9][0-9]:
\end{verbatim}
\afterverb
%
The translation of this regular expression is that we are looking for lines that start with ``From '' (note the space) followed by any number of characters ``.*'' followed by a space followed by two digits ``[0-9][0-9]'' followed by a colon character.  This is the definition of the kinds of lines we are looking for.  

In order to pull out only the hour using {\tt findall()}, we add parentheses around the two digits as follows:

\beforeverb
\begin{verbatim}
^From .* ([0-9][0-9]):
\end{verbatim}
\afterverb
%
This results in the following program:

\beforeverb
\begin{verbatim}
import re
hand = open('mbox-short.txt')
for line in hand:
    line = line.rstrip()
    x = re.findall('^From .* ([0-9][0-9]):', line)
    if len(x) > 0 : print x
\end{verbatim}
\afterverb
%
When the program runs, it produces the following output:

\beforeverb
\begin{verbatim}
['09']
['18']
['16']
['15']
...
\end{verbatim}
\afterverb
%
\section{Escape character}

Since we use special characters in regular expressions to match the beginning or end of 
a line or specify wild cards, we need a way to indicate that these characters are ``normal'' 
and we want to match the actual character such as a dollar-sign or caret.

We can indicate that we want to simply match a character by prefixing that character 
with a backslash.  For example, we can find money amounts with the following regular
expression.

\beforeverb
\begin{verbatim}
import re
x = 'We just received $10.00 for cookies.'
y = re.findall('\$[0-9.]+',x)
\end{verbatim}
\afterverb
%
Since we prefix the dollar-sign with a backslash, it actually matches the dollar-sign
in the input string instead of matching the ``end of line'' and the rest of the regular
expression matches one or more digits or the period character.  {\em Note:} In between 
square brackets, characters are not ``special''.   So when we say ``[0-9.]'', it really 
means digits or a period.    Outside of square brackets, a period is the ``wild-card'' 
character and matches any character.  In between square brackets, the period is a period.

\section{Summary}

While this only scratched the surface of regular expressions, we have learned a bit about the language of regular expressions.  They are search strings that have special characters in them that communicate your wishes to the regular expression system as to what defines ``matching'' and what is extracted from the matched strings.  Here are some of those special characters and character sequences:

\verb"^" \newline
Matches the beginning of the line.

\$ \newline
Matches the end of the line.

. \newline
Matches any character (a wildcard).

{\textbackslash}s \newline
Matches a whitespace character.

{\textbackslash}S \newline
Matches a non-whitespace character (opposite of {\textbackslash}s).

* \newline
Applies to the immediately preceding character and indicates to match zero or more of the preceding character.

*? \newline
Applies to the immediately preceding character and indicates to match zero or more of the preceding character in ``non-greedy mode''.

+ \newline
Applies to the immediately preceding character and indicates to match zero or more of the preceding character.

+? \newline
Applies to the immediately preceding character and indicates to match zero or more of the preceding character in ``non-greedy mode''.

[aeiou] \newline
Matches a single character as long as that character is in the specified set.  In this example, it would match ``a'', ``e'', ``i'', ``o'' or ``u'' but no other characters.

[a-z0-9] \newline
You can specify ranges of characters using the minus sign.  This example is a single character that must be a lower case letter or a digit.

[\verb"^"A-Za-z] \newline
When the first character in the set notation is a caret, it inverts the logic.  This example matches a single character that is anything {\em other than} an upper or lower case character.

( ) \newline
When parentheses are added to a regular expression, they are ignored for the purpose of matching, but allow you to extract a particular subset of the matched string rather than the whole string when using {\tt findall()}.

{\textbackslash}b \newline
Matches the empty string, but only at the start or end of a word.

{\textbackslash}B \newline
Matches the empty string, but not at the start or end of a word.

{\textbackslash}d \newline
Matches any decimal digit; equivalent to the set [0-9].

{\textbackslash}D \newline
Matches any non-digit character; equivalent to the set [\verb"^"0-9].

\section{Bonus section for Unix users}

Support for searching files using regular expressions was built into the Unix operating system 
since the 1960's and it is available in nearly all programming languages in one form or another.

\index{grep}
As a matter of fact, there is a command-line program built into Unix 
called {\bf grep} (Generalized Regular Expression Parser) that does pretty much 
the same as the {\tt search()} examples in this chapter.  So if you have a 
Macintosh or Linux system, you can try the following commands in your command line window.

\beforeverb
\begin{verbatim}
$ grep '^From:' mbox-short.txt
From: stephen.marquard@uct.ac.za
From: louis@media.berkeley.edu
From: zqian@umich.edu
From: rjlowe@iupui.edu
\end{verbatim}
\afterverb
%
This tells {\tt grep} to show you lines that start with the string ``From:'' in the file {\tt mbox-short.txt}.   If you experiment with the {\tt grep} command a bit and read the documentation for {\tt grep}, you will find some subtle differences between the regular expression support in Python and the regular expression support in {\tt grep}.  As an example, {\tt grep} does not support the non-blank character ``{\textbackslash}S'' so you will need to use the slightly more complex set notation ``[\verb"^" ]''- which simply means - match a character that is anything other than a space.

\section{Debugging}

Python has some simple and rudimentary built-in documentation that can be quite helpful if you need a quick refresher to trigger your memory about the exact name of a particular method.   This documentation can be viewed in the Python interpreter in interactive mode.

You can bring up an interactive help system using {\tt help()}.

\beforeverb
\begin{verbatim}
>>> help()

Welcome to Python 2.6!  This is the online help utility.

If this is your first time using Python, you should definitely check out
the tutorial on the Internet at http://docs.python.org/tutorial/.

Enter the name of any module, keyword, or topic to get help on writing
Python programs and using Python modules.  To quit this help utility and
return to the interpreter, just type "quit".

To get a list of available modules, keywords, or topics, type "modules",
"keywords", or "topics".  Each module also comes with a one-line summary
of what it does; to list the modules whose summaries contain a given word
such as "spam", type "modules spam".

help> modules
\end{verbatim}
\afterverb
%
If you know what module you want to use, you can use the {\tt dir()} command to find the methods in the module as follows:

\beforeverb
\begin{verbatim}
>>> import re
>>> dir(re)
[.. 'compile', 'copy_reg', 'error', 'escape', 'findall', 
'finditer', 'match', 'purge', 'search', 'split', 'sre_compile', 
'sre_parse', 'sub', 'subn', 'sys', 'template']
\end{verbatim}
\afterverb
%
You can also get a small amount of documentation on a particular method using the dir command.

\beforeverb
\begin{verbatim}
>>> help (re.search)
Help on function search in module re:

search(pattern, string, flags=0)
    Scan through string looking for a match to the pattern, returning
    a match object, or None if no match was found.
>>> 
\end{verbatim}
\afterverb
%
The built in documentation is not very extensive, but it can be helpful when you are in a hurry
or don't have access to a web browser or search engine.

\section{Glossary}

\begin{description}

\item[brittle code:]
Code that works when the input data is in a particular format but prone to breakage
if there is some deviation from the correct format.  We call this ``brittle code'' 
because it is easily broken.

\item[greedy matching:]
The notion that the ``+'' and ``*'' characters in a regular expression expand outward to match the largest possible string.
\index{greedy}
\index{greedy matching}

\item[grep:]
A command available in most Unix systems that searches through text files looking for lines that match regular expressions.  The command name stands for "Generalized Regular Expression Parser".
\index{grep}

\item[regular expression:]
A language for expressing more complex search strings.  A regular expression may contain special characters that indicate that a search only matches at the beginning or end of a line or many other similar capabilities.

\item[wild card:]
A special character that matches any character.   In regular expressions the wild card character is the period character.
\index{wild card}

\end{description}

\section{Exercises}

\begin{ex}
Write a simple program to simulate the operation of the {\tt grep} command 
on Unix.  Ask the user to enter a regular expression and count the number
of lines that matched the regular expression:

\beforeverb
\begin{verbatim}
$ python grep.py
Enter a regular expression: ^Author
mbox.txt had 1798 lines that matched ^Author

$ python grep.py
Enter a regular expression: ^X-
mbox.txt had 14368 lines that matched ^X-

$ python grep.py
Enter a regular expression: java$
mbox.txt had 4218 lines that matched java$
\end{verbatim}
\afterverb
%
\end{ex}

\begin{ex}
Write a program to look for lines of the form

\verb"New Revision: 39772"

And extract the number from each of the lines using a regular expression
and the {\tt findall()} method.  Compute the average of the numbers and 
print out the average.

\beforeverb
\begin{verbatim}
Enter file:mbox.txt 
38549.7949721

Enter file:mbox-short.txt
39756.9259259
\end{verbatim}
\afterverb
%

\end{ex}

\chapter{Networked programs}

While many of the examples in this book have focused on reading
files and looking for data in those files, there are many different
sources of information when one considers the Internet.

In this chapter we will pretend to be a web browser and retrieve web
pages using the HyperText Transport Protocol (HTTP).  Then we will read
through the web page data and parse it.

\section{HyperText Transport Protocol - HTTP}

The network protocol that powers the web is actually quite simple and 
there is built-in support in Python called {\tt sockets} which makes it very 
easy to make network connections and retrieve data over those
sockets in a Python program.

A {\bf socket} is much like a file, except that it 
provides a two-way connection between two 
programs with a single socket.  
You can both read from and write to the same socket.  If you write something to 
a socket it is sent to the application at the other end of the socket.  If you 
read from the socket, you are given the data which the other application has sent.

But if you try to read a socket when the program on the other end of the socket
has not sent any data - you just sit and wait.  If the programs on both ends
of the socket simply wait for some data without sending anything, they will wait for
a very long time.

So an important part of programs that communicate over the Internet is to have some
sort of protocol.   A protocol is a set of precise rules that determine who
is to go first, what they are to do, and then what are the responses to that message,
and who sends next and so on.  In a sense the two applications at either end 
of the socket are doing a dance and making sure not to step on each other's toes.

There are many documents which describe these network protocols.  The HyperText Transport 
Protocol is described in the following document:

\url{http://www.w3.org/Protocols/rfc2616/rfc2616.txt}

This is a long and complex 176 page document with a lot of detail.  If you 
find it interesting feel free to read it all.  But if you take a look around page 36 of
RFC2616 you will find the syntax for the GET request.  If you read in detail, you will
find that to request a document from a web server, we make a connection to 
the {\tt www.py4inf.com} server on port 80, and then send a line of the form:

{\tt GET http://www.py4inf.com/code/romeo.txt HTTP/1.0 }

Where the second parameter is the web page we are requesting and then 
we also send a blank line.  The web server will respond with some 
header information about the document and a blank line
followed by the document content.

\section{The World's Simplest Web Browser}

Perhaps the easiest way to show how the HTTP protocol works is to write a very 
simple Python program that makes a connection to a web server and following
the rules of the HTTP protocol, requests a document 
and displays what the server sends back.

\beforeverb
\begin{verbatim}
import socket

mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
mysock.connect(('www.py4inf.com', 80))
mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\n\n')

while True:
    data = mysock.recv(512)
    if ( len(data) < 1 ) :
        break
    print data

mysock.close()
\end{verbatim}
\afterverb
%
First the program makes a connection to port 80 on 
the server \url{www.py4inf.com}.
Since our program is playing the role of the ``web browser'' the HTTP
protocol says we must send the GET command followed by a blank line.

\beforefig
\centerline{\includegraphics[height=1.50in]{figs2/socket.eps}}
\afterfig

Once we send that blank line, we write a loop that receives data 
in 512 character chunks from the socket and prints the data out 
until there is no more data to read (i.e. the recv() returns 
an empty string).

The program produces the following output:

\beforeverb
\begin{verbatim}
HTTP/1.1 200 OK
Date: Sun, 14 Mar 2010 23:52:41 GMT
Server: Apache
Last-Modified: Tue, 29 Dec 2009 01:31:22 GMT
ETag: "143c1b33-a7-4b395bea"
Accept-Ranges: bytes
Content-Length: 167
Connection: close
Content-Type: text/plain

But soft what light through yonder window breaks
It is the east and Juliet is the sun
Arise fair sun and kill the envious moon
Who is already sick and pale with grief
\end{verbatim}
\afterverb
%
The output starts with headers which the web server sends
to describe the document.
For example, the {\tt Content-Type } header indicated that
the document is a plain text document ({\tt text/plain}).

After the server sends us the headers, it adds a blank line
to indicate the end of the headers and then sends the actual
data of the file {\tt romeo.txt}.

This example shows how to make a low-level network connection
with sockets.   Sockets can be used to communicate with a web
server or with a mail server or many other kinds of servers.
All that is needed is to find the document which describes
the protocol and write the code to send and receive the data
according to the protocol.

However, since the protocol that we use most commonly is
the HTTP (i.e. the web) protocol, Python has a special 
library specifically designed to support the HTTP protocol 
for the retrieval of
documents and data over the web.

\section{Retrieving an image over HTTP}

\index{urllib!image}
\index{image!jpg}
\index{jpg}
In the above example, we retrieved a plain text file 
which had newlines in the file and we simply copied the
data to the screen as the program ran.   We can use a similar
program to retrieve an image across using HTTP.   Instead
of copying the data to the screen as the program runs,
we accumulate the data in a string, trim off the headers
and then save the image data to a file as follows:

\beforeverb
\begin{verbatim}
import socket
import time

mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
mysock.connect(('www.py4inf.com', 80))
mysock.send('GET http://www.py4inf.com/cover.jpg HTTP/1.0\n\n')


count = 0
picture = "";
while True:
    data = mysock.recv(5120)
    if ( len(data) < 1 ) : break
    # time.sleep(0.25)
    count = count + len(data)
    print len(data),count
    picture = picture + data

mysock.close()

# Look for the end of the header (2 CRLF)
pos = picture.find("\r\n\r\n");
print 'Header length',pos
print picture[:pos]

# Skip past the header and save the picture data
picture = picture[pos+4:]
fhand = open("stuff.jpg","wb")
fhand.write(picture);
fhand.close()
\end{verbatim}
\afterverb
%
When the program runs it produces the following output:

\beforeverb
\begin{verbatim}
$ python urljpeg.py 
2920 2920
1460 4380
1460 5840
1460 7300
...
1460 62780
1460 64240
2920 67160
1460 68620
1681 70301
Header length 240
HTTP/1.1 200 OK
Date: Sat, 02 Nov 2013 02:15:07 GMT
Server: Apache
Last-Modified: Sat, 02 Nov 2013 02:01:26 GMT
ETag: "19c141-111a9-4ea280f8354b8"
Accept-Ranges: bytes
Content-Length: 70057
Connection: close
Content-Type: image/jpeg
\end{verbatim}
\afterverb
%
You can see that for this url, the 
{\tt Content-Type } header indicates that
body of the document is an image ({\tt image/jpeg}).
Once the program completes, you can view the image data by opening
the file {\tt stuff.jpg} in an image viewer.

As the program runs, 
can see that we don't get 5120 characters each time we 
call the {\tt recv()} method.
We get as many characters that have been transferred across the network 
to us by the web server at the moment we call {\tt recv()}.  
In this example, we either get 1460 or
2920 characters each time we request up to 5120 characters of data.

Your results may be different depending on your network speed.  Also
note that on the last call to {\tt recv()} we get 1681 bytes which is the end
of the stream and in the next call to {\tt recv()} we get a zero length
string that tells us that the server has called {\tt close()} on its end 
of the socket and there is no more data forthcoming.

\index{time}
\index{time.sleep}
We can slow down our successive calls {\tt recv()} by uncommmenting the call 
to {\tt time.sleep()}.  This way, we wait a quarter of a second after each call
so that the server can ``get ahead'' of us and send more data to us
before we call {\tt recv()}.  With the delay in place the program 
executes as follows:
\beforeverb
\begin{verbatim}
$ python urljpeg.py 
1460 1460
5120 6580
5120 11700
...
5120 62900
5120 68020
2281 70301
Header length 240
HTTP/1.1 200 OK
Date: Sat, 02 Nov 2013 02:22:04 GMT
Server: Apache
Last-Modified: Sat, 02 Nov 2013 02:01:26 GMT
ETag: "19c141-111a9-4ea280f8354b8"
Accept-Ranges: bytes
Content-Length: 70057
Connection: close
Content-Type: image/jpeg
\end{verbatim}
\afterverb
%
Now other than the first and last calls to {\tt recv()}, we now get 
5120 characters each time we ask for new data.  

There is a buffer between the server making {\tt send()} requests 
and our application making {\tt recv()} requests.  When we run the 
program with the delay in place, at some point the server might 
fill up the buffer in the socket and be forced to pause until our
program starts to empty the buffer.  The pausing of either the 
sending application or the receiving application is called 
``flow control''.
\index{flow control}

\section{Retrieving web pages with {\tt urllib}}

While we can manually send and receive data over HTTP 
using the socket library, there is a much simpler way to 
perform this common task in Python by 
using the {\tt urllib} library.

Using {\tt urllib},
you can treat a web page much like a file.   You simply
indicate which web page you would like to retrieve and
{\tt urllib} handles all of the HTTP protocol and header 
details.

The equivalent code to read the {\tt romeo.txt} file
from the web using {\tt urllib} is as follows:

\beforeverb
\begin{verbatim}
import urllib

fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt')
for line in fhand:
   print line.strip()
\end{verbatim}
\afterverb
%
Once the web page has been opened with 
{\tt urllib.urlopen} we can treat it like 
a file and read through it using a 
{\tt for} loop.   

When the program runs, we only see the output
of the contents of the file.   The headers
are still sent, but the {\tt urllib} code
consumes the headers and only returns the 
data to us.

\beforeverb
\begin{verbatim}
But soft what light through yonder window breaks
It is the east and Juliet is the sun
Arise fair sun and kill the envious moon
Who is already sick and pale with grief
\end{verbatim}
\afterverb
%

As an example, we can write 
a program to retrieve the data for
{\tt romeo.txt} and compute the frequency
of each word in the file as follows:

\beforeverb
\begin{verbatim}
import urllib

counts = dict()
fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt')
for line in fhand:
    words = line.split()
    for word in words:
        counts[word] = counts.get(word,0) + 1   
print counts
\end{verbatim}
\afterverb
%
Again, once we have opened the web page, 
we can read it like a local file.

\section{Parsing HTML and scraping the web}
\index{web!scraping}
\index{parsing HTML}

One of the common uses of the {\tt urllib} capability in Python is 
to {\bf scrape} the web.   Web scraping is when we write a program
that pretends to be a web browser and retrieves pages and then 
examines the data in those pages looking for patterns.

As an example, a search engine such as Google will look at the source 
of one web page and extract the links to other pages and retrieve
those pages, extracting links, and so on.   Using this technique,
Google {\bf spiders} its way through nearly all of the pages on 
the web.   

Google also uses the frequency of links from pages it finds 
to a particular page as one measure of how ``important'' 
a page is and how highly the page should appear in its search results.

\section{Parsing HTML using Regular Expressions}

One simple way to parse HTML is to use regular expressions to repeatedly
search and extract for substrings that match a particular pattern.

Here is a simple web page:

\beforeverb
\begin{verbatim}
<h1>The First Page</h1>
<p>
If you like, you can switch to the
<a href="http://www.dr-chuck.com/page2.htm">
Second Page</a>.
</p>
\end{verbatim}
\afterverb
%
We can construct a well-formed regular expression to match
and extract the link values from the above text as follows:

\beforeverb
\begin{verbatim}
href="http://.+?"
\end{verbatim}
\afterverb
%
Our regular expression looks for strings that start with
``href="http://'' followed by one or more characters
``.+?'' followed by another double quote.  The question mark 
added to the ``.+?'' indicates that the match is to be done
in a ``non-greedy'' fashion instead of a ``greedy'' fashion.  
A non-greedy match tries to find the {\em smallest} possible matching
string and a greedy match tries to find the {\em largest} possible
matching string.
\index{greedy}
\index{non-greedy}

We need to add parentheses to our regular expression to indicate
which part of our matched string we would like to extract and
produce the following program:
\index{regex!parentheses}
\index{parentheses!regular expression}

\beforeverb
\begin{verbatim}
import urllib
import re

url = raw_input('Enter - ')
html = urllib.urlopen(url).read()
links = re.findall('href="(http://.*?)"', html)
for link in links:
    print link
\end{verbatim}
\afterverb
%
The {\tt findall} regular expression method will give us a list of all
of the strings that match our regular expression, returning only
the link text between the double quotes.

When we run the program, we get the following output:

\beforeverb
\begin{verbatim}
python urlregex.py 
Enter - http://www.dr-chuck.com/page1.htm
http://www.dr-chuck.com/page2.htm

python urlregex.py 
Enter - http://www.py4inf.com/book.htm
http://www.greenteapress.com/thinkpython/thinkpython.html
http://allendowney.com/
http://www.py4inf.com/code
http://www.lib.umich.edu/espresso-book-machine
http://www.py4inf.com/py4inf-slides.zip
\end{verbatim}
\afterverb
%
Regular expressions work very nice when your HTML is well-formatted
and predictable.  But since there is a lot of ``broken'' HTML pages
out there, you might find that a solution only using 
regular expressions might either miss some valid links or end up 
with bad data.

This can be solved by using a robust HTML parsing library.

\section{Parsing HTML using BeautifulSoup}
\index{BeautifulSoup}

There are a number of Python libraries which can help you parse
HTML and extract data from the pages.  Each of the libraries
has its strengths and weaknesses and you can pick one based on 
your needs.

As an example, we will simply parse some HTML input 
and extract links using the {\bf BeautifulSoup} library.   
You can download and install the BeautifulSoup code
from:

\url{www.crummy.com}

You can download and ``install'' BeautifulSoup or you 
can simply place the {\tt BeautifulSoup.py} file in the
same folder as your application.

Even though HTML looks like XML and some pages are carefully 
constructed to be XML, most HTML is generally broken in ways
that cause an XML parser to reject the entire page of HTML as
improperly formed.  BeautifulSoup tolerates highly flawed 
HTML and still lets you easily extract the data you need.

We will use {\tt urllib} to read the page and then use
{\tt BeautifulSoup} to extract the {\tt href} attributes from the
anchor ({\tt a}) tags.
\index{BeautifulSoup}
\index{HTML}
\index{parsing!HTML}

\beforeverb
\begin{verbatim}
import urllib
from BeautifulSoup import *

url = raw_input('Enter - ')
html = urllib.urlopen(url).read()
soup = BeautifulSoup(html)

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
   print tag.get('href', None)
\end{verbatim}
\afterverb
%
The program prompts for a web address, then opens the web
page, reads the data and passes the data to the BeautifulSoup
parser, and then retrieves all of the anchor tags and prints
out the {\tt href} attribute for each tag.

When the program runs it looks as follows:

\beforeverb
\begin{verbatim}
python urllinks.py 
Enter - http://www.dr-chuck.com/page1.htm
http://www.dr-chuck.com/page2.htm

python urllinks.py 
Enter - http://www.py4inf.com/book.htm
http://www.greenteapress.com/thinkpython/thinkpython.html
http://allendowney.com/
http://www.si502.com/
http://www.lib.umich.edu/espresso-book-machine
http://www.py4inf.com/code
http://www.pythonlearn.com/
\end{verbatim}
\afterverb
%
You can use BeautifulSoup to pull out various parts of each 
tag as follows:

\beforeverb
\begin{verbatim}
import urllib
from BeautifulSoup import *

url = raw_input('Enter - ')
html = urllib.urlopen(url).read()
soup = BeautifulSoup(html)

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
   # Look at the parts of a tag
   print 'TAG:',tag
   print 'URL:',tag.get('href', None)
   print 'Content:',tag.contents[0]
   print 'Attrs:',tag.attrs
\end{verbatim}
\afterverb
%
This produces the following output:

\beforeverb
\begin{verbatim}
python urllink2.py 
Enter - http://www.dr-chuck.com/page1.htm
TAG: <a href="http://www.dr-chuck.com/page2.htm">
Second Page</a>
URL: http://www.dr-chuck.com/page2.htm
Content: [u'\nSecond Page']
Attrs: [(u'href', u'http://www.dr-chuck.com/page2.htm')]
\end{verbatim}
\afterverb
%
These examples only begin to show the power of BeautifulSoup
when it comes to parsing HTML.  See the documentation 
and samples at
\url{www.crummy.com}
for more detail.

\section{Reading binary files using urllib}

Sometimes you want to retrieve a non-text (or binary) file such as
an image or video file. The data in these files is generally not 
useful to print out but you can easily make a copy of a URL to a local
file on your hard disk using {\tt urllib}.
\index{binary file}

The pattern is to open the URL and use {\tt read} to download the entire
contents of the document into a string variable ({\tt img}) and then write that
information to a local file as follows:

\beforeverb
\begin{verbatim}
img = urllib.urlopen('http://www.py4inf.com/cover.jpg').read()
fhand = open('cover.jpg', 'w')
fhand.write(img)
fhand.close()
\end{verbatim}
\afterverb
%
This program reads all of the data in at once across the network and 
stores it in the variable {\tt img} in the main memory of your computer
and then opens the file {\tt cover.jpg} and writes the data out to your 
disk.  This will work if the size of the file is less than the size
of the memory of your computer.

However if this is a large audio or video file, this program may crash
or at least run extremely slowly when your computer runs out of memory.
In order to avoid running out of memory, we retrieve the data in blocks
(or buffers) and then write each block to your disk before retrieving
the next block.  This way the program can read any sized file without
using up all of the memory you have in your computer.

\beforeverb
\begin{verbatim}
import urllib

img = urllib.urlopen('http://www.py4inf.com/cover.jpg')
fhand = open('cover.jpg', 'w')
size = 0
while True:
    info = img.read(100000)
    if len(info) < 1 : break
    size = size + len(info)
    fhand.write(info)

print size,'characters copied.'
fhand.close()
\end{verbatim}
\afterverb
%
In this example, we read only 100,000 characters at a time and then 
write those characters to the {\tt cover.jpg} file
before retrieving the next 100,000 characters of data from the
web.

This program runs as follows:

\beforeverb
\begin{verbatim}
python curl2.py 
568248 characters copied.
\end{verbatim}
\afterverb
%

If you have a Unix or Macintosh computer, you probably have a command
built into your operating system that performs this operation
as follows:
\index{curl}

\beforeverb
\begin{verbatim}
curl -O http://www.py4inf.com/cover.jpg
\end{verbatim}
\afterverb
%
The command {\tt curl} is short for ``copy URL'' and so these two 
examples are cleverly named {\tt curl1.py} and {\tt curl2.py} on 
\url{www.py4inf.com/code} as they implement similar functionality
to the {\tt curl} command.  There is also a {\tt curl3.py} sample 
program that does this task a little more effectively in case you
actually want to use this pattern in a program you are writing.

\section{Glossary}

\begin{description}

\item[BeautifulSoup:] A Python library for parsing HTML documents
and extracting data from HTML documents
that compensates for most of the imperfections in the HTML that browsers
generally ignore.
You can download the BeautifulSoup code
from 
\url{www.crummy.com}.
\index{BeautifulSoup}

\item[port:] A number that generally indicates which application 
you are contacting when you make a socket connection to a server.
As an example, web traffic usually uses port 80 while e-mail 
traffic uses port 25.
\index{port}

\item[scrape:] When a program pretends to be a web browser and
retrieves a web page and then looks at the web page content. 
Often programs are following the links in one page to find the next
page so they can traverse a network of pages or a social network.
\index{socket}

\item[socket:] A network connection between two applications
where the applications can send and receive data in either direction.
\index{socket}

\item[spider:] The act of a web search engine retrieving a page and
then all the pages linked from a page and so on until they have 
nearly all of the pages on the Internet which they 
use to build their search index.
\index{spider}

\end{description}

\section{Exercises}

\begin{ex}
Change the socket program {\tt socket1.py} to prompt the user for 
the URL so it can read any web page.  
You can use {\tt split('/')} to break the URL into its component parts
so you can extract the host name for the socket {\tt connect} call.
Add error checking using {\tt try} and {\tt except} to handle the condition where the 
user enters an improperly formatted or non-existent URL.  
\end{ex}

\begin{ex}
Change your socket program so that it counts the number of characters it has received 
and stops displaying any text after it has shown 3000 characters.  The program 
should retrieve the entire document and count the total number of characters 
and display the count of the number of characters at the end of the document.
\end{ex}

\begin{ex}
Use {\tt urllib} to replicate the previous exercise of (1) retrieving the document
from a URL, (2) displaying up to 3000 characters, and (3) counting the overall number
of characters in the document.  Don't worry about the headers for this exercise, simply
show the first 3000 characters of the document contents.
\end{ex}

\begin{ex}
Change the {\tt urllinks.py} program to extract and count 
paragraph (p) tags from the retrieved HTML document and 
display the count of the paragraphs as the 
output of your program.  
Do not display the paragraph text - only count them.
Test your program on several small web pages
as well as some larger web pages.
\end{ex}

\begin{ex}
(Advanced) Change the socket program so that it only shows data after the 
headers and a blank line have been received.  Remember that {\tt recv} is
receiving characters (newlines and all) - not lines.
\end{ex}


\chapter{Using Web Services}

Once it became easy to retrieve documents and parse documents 
over HTTP using programs, it did not take long to develop 
an approach where we started producing documents that were specifically
designed to be consumed by other 
programs (i.e. not HTML to be displayed in a browser).

There are two common formats that we use when exchanging data across the web.
The ``eXtensible Markup Language'' or XML has been in use for a very long time 
and is best suited for exchanging document-style data.   When programs just want 
to exchange dictionaries, lists, or other internal information with each other,
they use JavaScript Object Notation or JSON (see \url{www.json.org}).  
We will look at both formats.

\section{eXtensible Markup Language - XML}

XML looks very similar to HTML, but XML is more structured 
than HTML.  Here is a sample of an XML document:

\beforeverb
\begin{verbatim}
<person>
  <name>Chuck</name>
  <phone type="intl">
     +1 734 303 4456
   </phone>
   <email hide="yes"/>
</person>
\end{verbatim}
\afterverb
%
Often it is helpful to think of an XML document as a tree structure
where there is a top tag {\tt person} and other tags such as {\tt phone}
are drawn as \emph{children} of their parent nodes.

\beforefig
\centerline{\includegraphics[height=1.50in]{figs2/xml-tree.eps}}
\afterfig

\section{Parsing XML}

\index{ElementTree}
\index{ElementTree!fromstring}
\index{ElementTree!find}
Here is a simple application that parses some XML
and extracts some data elements from the XML:

\beforeverb
\begin{verbatim}
import xml.etree.ElementTree as ET

data = '''
<person>
  <name>Chuck</name>
  <phone type="intl">
     +1 734 303 4456
   </phone>
   <email hide="yes"/>
</person>'''

tree = ET.fromstring(data)
print 'Name:',tree.find('name').text
print 'Attr:',tree.find('email').get('hide')
\end{verbatim}
\afterverb
%
Calling {\tt fromstring} converts the string representation
of the XML into a 'tree' of XML nodes.  When the
XML is in a tree, we have a series of methods which we can call to 
extract portions of data from the XML.  

The {\tt find} function searches through the 
XML tree and retrieves a {\bf node} that matches the specified tag.
Each node can have some text, some attributes (i.e. like hide) and
some ``child'' nodes.   Each node can be the top of a tree of nodes.

\beforeverb
\begin{verbatim}
Name: Chuck
Attr: yes
\end{verbatim}
\afterverb
%
Using an XML parser such as {\tt ElementTree} has the advantage
that while the XML in this example is quite simple, it turns
out there are many rules regarding valid XML and using 
{\tt ElementTree} allows us to extract data from XML without 
worrying about the rules of XML syntax.

\section{Looping through nodes}

\index{ElementTree!findall}
\index{ElementTree!get}
Often the XML has multiple nodes and we need to write a loop
to process all of the nodes.  In the following program, 
we loop through all of the {\tt user} nodes:

\beforeverb
\begin{verbatim}
import xml.etree.ElementTree as ET

input = '''
<stuff>
    <users>
        <user x="2">
            <id>001</id>
            <name>Chuck</name>
        </user>
        <user x="7">
            <id>009</id>
            <name>Brent</name>
        </user>
    </users>
</stuff>'''

stuff = ET.fromstring(input)
lst = stuff.findall('users/user')
print 'User count:', len(lst)

for item in lst:
    print 'Name', item.find('name').text
    print 'Id', item.find('id').text
    print 'Attribute', item.get('x')
\end{verbatim}
\afterverb
%
The {\tt findall} method retrieves a Python list of sub-trees that
represent the {\tt user} structures in the XML tree.  Then we can 
write a {\tt for} loop that looks at each of the user nodes, and 
prints the {\tt name} and {\tt id} text elements as well as the 
{\tt x} attribute from the {\tt user} node.

\beforeverb
\begin{verbatim}
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
\end{verbatim}
\afterverb
%

\section{JavaScript Object Notation - JSON}
\index{JSON}
\index{JavaScript Object Notation}

The JSON format was inspired by the object and array format used in the JavaScript
language.  But since Python was invented before JavaScript, Python's syntax
for dictionaries and lists influenced the syntax of JSON.  So the format of JSON
is nearly identical to a combination of Python lists and dictionaries.

Here is a JSON encoding that is roughly equivalent to the simple XML from above:

\beforeverb
\begin{verbatim}
{
  "name" : "Chuck",
  "phone" : {
    "type" : "intl",
    "number" : "+1 734 303 4456"
   },
   "email" : {
     "hide" : "yes"
   }
}
\end{verbatim}
\afterverb
%
You will notice some differences.  First, in XML, we can add attributes like
``intl'' to the ``phone'' tag.  In JSON we simply have key-value pairs.  Also
the XML ``person'' tag is gone, replaced by a set of outer curly-braces.  

In general JSON structures are simpler than XML because JSON has fewer capabilities
than XML.  But JSON has the advantage that it maps {\em directly} to some combination
of dictionaries and lists.   And since nearly all programming languages 
have something equivalent to Python's dictionaries and lists, JSON is a very
natural format to have two cooperating programs exchange data.

JSON is quickly becoming the format of choice for nearly all data exchange between 
applications because of its relative simplicity compared to XML.

\section{Parsing JSON}

We construct our JSON by nesting dictionaries (objects) and lists as needed.  In 
this example we represent a list of users where each user is a set of 
key value pairs (i.e. a dictionary).  So we have a list of dictionaries.

In the following program, we use the built-in {\bf json} library parse 
the JSON and read through the data.   Compare this closely to the equivalent
XML data and code above.  The JSON has less detail so we must know in advance 
that we are getting a list, and the list is of users and each user is a set of 
key value pairs.  The JSON is more succinct (an advantage) but also is 
less self-describing (a disadvantage).

\beforeverb
\begin{verbatim}
import json

input = '''
[
  { "id" : "001",
    "x" : "2",
    "name" : "Chuck"
  } ,
  { "id" : "009",
    "x" : "7",
    "name" : "Chuck"
  } 
]'''

info = json.loads(input)
print 'User count:', len(info)

for item in info:
    print 'Name', item['name']
    print 'Id', item['id']
    print 'Attribute', item['x']
\end{verbatim}
\afterverb
%

If you compare the code to extract data from the parsed JSON and XML
you will see that what we get from {\bf json.loads()} 
is a Python list which we traverse with 
a {\bf for} loop and each item within that list
is a Python dictionary which we use the Python
index operator to extract the various bits of each user.   Once the JSON has
been parsed - we simply have native Python objects and structures.  We don't
have to use the JSON library to dig through the parsed JSON since the returned
data is simply native Python structures.

The output of this program is exactly the same as the XML version above.

\beforeverb
\begin{verbatim}
User count: 2
Name Chuck
Id 001
Attribute 2
Name Brent
Id 009
Attribute 7
\end{verbatim}
\afterverb
%
In general, there is an industry trend away from XML and towards JSON for 
web services.  Because the JSON is simpler and more directly maps to native 
data structures we already have in programming languages, the parsing 
and data extraction code is usually simpler and more direct when using JSON.
But XML is more self-descriptive than JSON and so there are 
some applications where XML retains an advantage.  For example, most word 
processors store documents internally using XML rather than JSON.

\section{Application Programming Interfaces (API)}

We now have the ability to exchange data between applications using HyperText
Transport Protocol (HTTP) and a way to represent complex data that we are 
sending back and forth between these applications using eXtensible 
Markup Language (XML) or JavaScript Object Notation (JSON).

The next step is to begin to define and document ``contracts'' between 
applications using these techniques. The general name for these 
application-to-application contracts is {\bf Application Program 
Interfaces} or APIs.  When we use an API, generally one program
makes a set of {\bf services} available for use by other applications
and publishes the APIs (i.e. the ``rules'') that must be followed to 
access the services provided by the program.

When we begin to build our programs where the functionality of
our program includes access to services provided by other programs, 
we call the approach a {\bf Service-Oriented Architecture} or SOA.
A SOA approach is one where our overall application makes use of 
the services of other applications.  A non-SOA approach is where the
application is a single stand-alone application which contains all of the
code necessary to implement the application.

We see many examples of SOA when we use the web.  We can go to a single 
web site and book air travel, hotels, and automobiles all from a 
single site.  The data for hotels is not stored on the airline computers. 
Instead, the airline computers contact the services on the hotel computers
and retrieve the hotel data and present it to the user.  When the user
agrees to make a hotel reservation using the airline site, the airline site uses
another web service on the hotel systems to actually make the reservation.
And when it comes to charge your credit card for the whole transaction, 
still other computers become involved in the process.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/soa.eps}}
\afterfig

A Service-Oriented Architecture has many advantages including: (1) we 
always maintain only one copy of data - this is particularly important
for things like hotel reservations where we do not want to over-commit
and (2) the owners of the data can set the rules about the use of their 
data.   With these advantages, a SOA system must be carefully designed
to have good performance and meet the user's needs.

When an application makes a set of services in its API available over the web, 
we call these {\bf web services}. 

\section{Google geocoding web service}
\index{Google}
\index{geocoding}
\index{web service}

Google has an excellent web service that allows us to make use of their 
large database of geographic information.   We can submit a geographical
search string like ``Ann Arbor, MI'' to their geocoding API and have Google 
return its best guess as to where on a map we might find our search string and
tells us about the landmarks nearby.

The geocoding service is free but rate limited so you cannot make unlimited
use of the API in a commercial application.   But if you have some survey data
where an end-user has entered a location in a free-format input box, you can use
this API to clean up your data quite nicely.  

{\em When you are using a free API like Google's geocoding API, you need
to be respectful in your use of these resources.  If too many people abuse the
service, Google might drop or significantly curtail its free service.}
\index{rate limiting}

You can read the online documentation for this service, but it is quite simple
and you can even test it using a browser by typing the following URL into your 
browser:

\url{http://maps.googleapis.com/maps/api/geocode/json?sensor=false &address=Ann+Arbor%2C+MI}

Make sure to un-wrap the URL and remove any spaces from the URL before pasting
it into your browser.

The following is a simple application to prompt the user for a search string
and call the Google geocoding API and extract information from the returned
JSON.

\beforeverb
\begin{verbatim}
import urllib
import json

serviceurl = 'http://maps.googleapis.com/maps/api/geocode/json?'

while True:
    address = raw_input('Enter location: ')
    if len(address) < 1 : break

    url = serviceurl + urllib.urlencode({'sensor':'false', 
          'address': address})
    print 'Retrieving', url
    uh = urllib.urlopen(url)
    data = uh.read()
    print 'Retrieved',len(data),'characters'

    try: js = json.loads(str(data))
    except: js = None
    if 'status' not in js or js['status'] != 'OK':
        print '==== Failure To Retrieve ===='
        print data
        continue

    print json.dumps(js, indent=4)

    lat = js["results"][0]["geometry"]["location"]["lat"]
    lng = js["results"][0]["geometry"]["location"]["lng"]
    print 'lat',lat,'lng',lng
    location = js['results'][0]['formatted_address']
    print location
\end{verbatim}
\afterverb
%
The program takes the search string and constructs a URL with the
search string as a properly encoded parameter and then uses
{\bf urllib} to retrieve the text from the Google geocoding API.
Unlike a fixed web page, the data we get depends on the parameters
we send and the geographical data stored in Google's servers.

Once we retrieve the JSON data, we parse it with the {\bf json}
library and do a few checks to make sure that we received good data 
and then extract the information that we are looking for.

The output of the program is as follows (some of the returned
JSON has been removed):

\beforeverb
\begin{verbatim}
$ python geojson.py
Enter location: Ann Arbor, MI
Retrieving http://maps.googleapis.com/maps/api/
  geocode/json?sensor=false&address=Ann+Arbor%2C+MI
Retrieved 1669 characters
{
    "status": "OK", 
    "results": [
        {
            "geometry": {
                "location_type": "APPROXIMATE", 
                "location": {
                    "lat": 42.2808256, 
                    "lng": -83.7430378
                }
            }, 
            "address_components": [
                {
                    "long_name": "Ann Arbor", 
                    "types": [
                        "locality", 
                        "political"
                    ], 
                    "short_name": "Ann Arbor"
                } 
            ], 
            "formatted_address": "Ann Arbor, MI, USA", 
            "types": [
                "locality", 
                "political"
            ]
        }
    ]
}
lat 42.2808256 lng -83.7430378
Ann Arbor, MI, USA
Enter location:
\end{verbatim}
\afterverb
%
You can download 
\url{www.py4inf.com/code/geojson.py} and 
\url{www.py4inf.com/code/geoxml.py} to explore the JSON
and XML variants of the Google geocoding API. 

\section{Security and API usage}
\index{OAuth}
\index{API!key}

It is quite common that you need some kind of 
``API key'' to make use of a vendor's API.  The
general idea is that they want to know who is using 
their services and how much each user is using.  
Perhaps they have free and pay tiers of their services
or have a policy that limits the number of requests 
that a single individual can during a particular 
time period.

Sometimes once you get your API key, you simply include
the key as part of POST data or perhaps as a parameter
on the URL when calling the API.

Other times, the vendor wants increased assurance of
the source of the requests and so they add expect you 
to send cryptographically signed messages using shared
keys and secrets.   A very common technology that is used 
to sign requests over the Internet is called {\bf OAuth}.
You can read more about the OAuth protocol at
\url{http://www.oauth.net}.

As the Twitter API became increasingly valuable, Twitter
went from an open and public API to an API that required
the use of OAuth signatures on each API request. Thankfully
there are a number of convenient and free OAuth libraries

so you can avoid writing an OAuth implementation from scratch
by reading the specification.  These libraries are of 
varying complexity and have varying 
richness.  The OAuth web site has information about various 
OAuth libraries.

For this next sample program we will download these files: 
{\bf twurl.py}, {\bf hidden.py}, 
{\bf oauth.py}, 
and
{\bf twitter1.py} from 
\url{www.py4inf.com/code} and put them all in a folder
on your computer.

To make use of these programs you will need to have a Twitter
account, and authorize your Python code as an application,
set up a key, secret, token and token secret.  You will edit
the file {\bf hidden.py} and put these four strings into the
appropriate variables in the file:

\beforeverb
\begin{verbatim}
    def auth() :
        return { "consumer_key" : "h7L...GNg",
            "consumer_secret" : "dNK...7Q",
            "token_key" : "101...GI",
            "token_secret" : "H0yM...Bo" }
\end{verbatim}
\afterverb
%
The Twitter web service are accessed using a URL like this:

\url{https://api.twitter.com/1.1/statuses/user_timeline.json}

But once all of the security information has been added, the URL
will look more like:

\beforeverb
\begin{verbatim}
https://api.twitter.com/1.1/statuses/user_timeline.json?count=2
&oauth_version=1.0&oauth_token=101...SGI&screen_name=drchuck
&oauth_nonce=09239679&oauth_timestamp=1380395644
&oauth_signature=rLK...BoD&oauth_consumer_key=h7Lu...GNg
&oauth_signature_method=HMAC-SHA1
\end{verbatim}
\afterverb
%
You can read the OAuth specification if you want to
know more about the meaning of the various parameters that
are added to meet the security requirements of OAuth.  

For the programs we run with Twitter, we hide all the 
complexity in the files {\bf oauth.py} and {\bf twurl.py}.
We simply set the secrets in {\bf hidden.py} and then 
send the desired URL to the {\bf twurl.augment()} 
function and the library code adds all the necessary 
parameters to the URL for us.

This program ({\bf twitter1.py}) retrieves the timeline
for a particular Twitter user and returns it to us in JSON
format in a string.  We simply print the first 250 characters
of the string:

\beforeverb
\begin{verbatim}
import urllib
import twurl

TWITTER_URL='https://api.twitter.com/1.1/statuses/user_timeline.json'

while True:
    print ''
    acct = raw_input('Enter Twitter Account:')
    if ( len(acct) < 1 ) : break
    url = twurl.augment(TWITTER_URL,
        {'screen_name': acct, 'count': '2'} )
    print 'Retrieving', url
    connection = urllib.urlopen(url)
    data = connection.read()
    print data[:250]
    headers = connection.info().dict
    # print headers
    print 'Remaining', headers['x-rate-limit-remaining']
\end{verbatim}
\afterverb
%
When the program runs it produces the following output: 
 
\beforeverb
\begin{verbatim}
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 17:30:25 +0000 2013","
id":384007200990982144,"id_str":"384007200990982144",
"text":"RT @fixpert: See how the Dutch handle traffic 
intersections: http:\/\/t.co\/tIiVWtEhj4\n#brilliant",
"source":"web","truncated":false,"in_rep
Remaining 178

Enter Twitter Account:fixpert
Retrieving https://api.twitter.com/1.1/ ...
[{"created_at":"Sat Sep 28 18:03:56 +0000 2013",
"id":384015634108919808,"id_str":"384015634108919808",
"text":"3 months after my freak bocce ball accident, 
my wedding ring fits again! :)\n\nhttps:\/\/t.co\/2XmHPx7kgX",
"source":"web","truncated":false,
Remaining 177

Enter Twitter Account:
\end{verbatim}
\afterverb
%
Along with the returned timeline data, Twitter also returns
metadata about the request in the HTTP response headers. 
One header in particular, {\bf x-rate-limit-remaining} informs
us how many more requests we can make before we will be shut 
off for a short time period.  You can see that our remaining 
retrievals drop by one each time we make a request to the 
API.

In the following example, we retrieve a user's Twitter friends
and parse the returned JSON and extract some of the information
about the friends.  We also dump the JSON after parsing and
``pretty-print'' it with an indent of four characters to allow
us to pore through the data when we want to extract more fields.

\beforeverb
\begin{verbatim}
import urllib
import twurl
import json

TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'

while True:
    print ''
    acct = raw_input('Enter Twitter Account:')
    if ( len(acct) < 1 ) : break
    url = twurl.augment(TWITTER_URL,
        {'screen_name': acct, 'count': '5'} )
    print 'Retrieving', url
    connection = urllib.urlopen(url)
    data = connection.read()
    headers = connection.info().dict
    print 'Remaining', headers['x-rate-limit-remaining']
    js = json.loads(data)
    print json.dumps(js, indent=4)

    for u in js['users'] :
        print u['screen_name']
        s = u['status']['text']
        print '  ',s[:50]
\end{verbatim}
\afterverb
%
Since the JSON becomes a set of nested Python lists and dictionaries,
we can use a combination of the index operation and for loops to 
wander through the returned data structures with very little 
Python code.

The output of the program looks as follows (some of the data items 
are shortened to fit on the page):

\beforeverb
\begin{verbatim}
Enter Twitter Account:drchuck
Retrieving https://api.twitter.com/1.1/friends ...
Remaining 14
{
    "next_cursor": 1444171224491980205, 
    "users": [
        {
            "id": 662433, 
            "followers_count": 28725, 
            "status": {
                "text": "@jazzychad I just bought one .__.", 
                "created_at": "Fri Sep 20 08:36:34 +0000 2013", 
                "retweeted": false, 
            }, 
            "location": "San Francisco, California", 
            "screen_name": "leahculver", 
            "name": "Leah Culver", 
        }, 
        {
            "id": 40426722, 
            "followers_count": 2635, 
            "status": {
                "text": "RT @WSJ: Big employers like Google ...", 
                "created_at": "Sat Sep 28 19:36:37 +0000 2013", 
            }, 
            "location": "Victoria Canada", 
            "screen_name": "_valeriei", 
            "name": "Valerie Irvine", 
    ], 
    "next_cursor_str": "1444171224491980205"
}
leahculver
   @jazzychad I just bought one .__.
_valeriei
   RT @WSJ: Big employers like Google, AT&amp;T are h
ericbollens
   RT @lukew: sneak peek: my LONG take on the good &a
halherzog
   Learning Objects is 10. We had a cake with the LO,
scweeker
   @DeviceLabDC love it! Now where so I get that "etc

Enter Twitter Account:
\end{verbatim}
\afterverb
%
The last bit of the output is where we see the for loop reading the
five most recent ``friends'' of the {\bf drchuck} Twitter account 
and printing the most recent status for each friend. There is a 
great deal more data available in the returned JSON.  Also if you look
in the output of the program, you can see that the ``find the friends''
of a particular account has a different rate limitation than 
the number of timeline queries we are allowed to run per time period.

These secure API keys allow Twitter to have solid confidence that they 
know who is using their API and data and at what level.   The rate
limiting approach allows us to do simple, personal data retrievals but
does not allow us to build a product that pulls data from their API 
millions of times per day.

\section{Glossary}

\begin{description}

\item[API:] Application Program Interface - A contract between
applications that defines the patterns of interaction between 
two application components.
\index{API}

\item[ElementTree:] A built-in Python library used to parse XML data.
\index{ElementTree}

\item[JSON:] JavaScript Object Notation- A format that allows for 
the markup of structured data based on the syntax of JavaScript
Objects.
\index{JSON}
\index{JavaScript Object Notation}

\item[REST:] REpresentational State Transfer - A style of Web Services 
that provide access to resources within an application using the HTTP
protocol.
\index{ElementTree}

\item[SOA:] Service Oriented Architecture - when an application is 
made of components connected across a network.
\index{SOA}
\index{Service Oriented Architecture}

\item[XML:] eXtensible Markup Language - A format that allows for 
the markup of structured data.
\index{XML}
\index{eXtensible Markup Language}

\end{description}

\section{Exercises}

\begin{ex}
Change either the 
\url{www.py4inf.com/code/geojson.py} or
\url{www.py4inf.com/code/geoxml.py} to print out the 
two-character country code from the retrieved data.
Add error checking so your program does not traceback
if the country code is not there.  Once you have it 
working, search for ``Atlantic Ocean'' and make sure
it can handle locations that are not in any country.
\end{ex}

\chapter{Using databases and Structured Query Language (SQL)}

\section{What is a database?}
\index{database}

A {\bf database} is a file that is organized for storing data.
Most databases are organized like a dictionary in the sense
that they map from keys to values.  The biggest difference
is that the database is on disk (or other permanent storage),
so it persists after the program ends.  Because a database is
stored on permanent storage, it can store far more data than
a dictionary, which is limited to the size of the memory 
in the computer.

\index{database!indexes}
Like a dictionary, database software is designed to keep 
the inserting and accessing of data very fast, even for large
amounts of data.   Database software maintains its performance by 
building {\bf indexes} as data is added to the database
to allow the computer to jump quickly to a particular
entry.

There are many different database systems which are used for a wide
variety of purposes including: Oracle, MySQL, Microsoft SQL Server, 
PostgreSQL, and SQLite.  We focus on SQLite in this book because
it is a very common database and is already built into Python.  
SQLite is designed to be \emph{embedded} into other applications
to provide database support within the application.  For example,
the Firefox browser also uses the SQLite database internally as do 
many other products.

\url{http://sqlite.org/}

SQLite is well suited to some of the data manipulation problems that we 
see in Informatics such as the Twitter spidering application that we 
describe in this chapter.

\section{Database concepts}

When you first look at a database it looks like a 
spreadsheet with multiple sheets.   The primary data structures 
in a database are:
{\bf tables}, {\bf rows}, and {\bf columns}.  

\beforefig
\centerline{\includegraphics[height=1.50in]{figs2/relational.eps}}
\afterfig

In technical descriptions of relational databases the concepts of 
table, row, and column are more formally referred
to as {\bf relation}, {\bf tuple}, and {\bf attribute}, respectively.
We will use the less formal terms in this chapter.

\section{SQLite manager Firefox add-on}

While this chapter will focus on using Python to work with data 
in SQLite database files, many operations can be done more
conveniently using a Firefox add-on called the {\bf SQLite
Database Manager} which is freely available from:

\url{https://addons.mozilla.org/en-us/firefox/addon/sqlite-manager/}

Using the browser you can easily create tables, insert data, edit data, 
or run simple SQL queries on the data in the database.

In a sense, the database manager is similar to a text editor
when working with text files.   When you want to do one or
very few operations on a text file, you can just open it
in a text editor and make the changes you want.   When you have 
many changes that you need to do to a text file, often you 
will write a simple Python program.  You will find the same 
pattern when working with databases.  You will do simple
operations in the database manager and more complex operations
will be most conveniently done in Python.

\section{Creating a database table}

Databases require more defined structure than Python lists 
or dictionaries\footnote{SQLite actually does allow some 
flexibility in the type of data stored in a column,
but we will keep our data types strict in this chapter
so the concepts apply equally to other database systems 
such as MySQL.}.  

When we create a database {\bf table} we
must tell the database in advance the names of each of the
{\bf columns} in the table and the type of data which we are 
planning to store in each {\bf column}.   When the database software
knows the type of data in each column, it can choose the most 
efficient way to store and lookup the data based on the type of
data. 

You can look at the various data types supported by SQLite
at the following url:

\url{http://www.sqlite.org/datatypes.html}

Defining structure for your data up front may seem inconvenient
at the beginning, but the payoff is fast access to your data 
even when the database contains a large amount of data.

The code to create a database file and a table 
named {\tt Tracks} with two columns in the 
database is as follows:

\index{sqlite3 module}
\index{module!sqlite3}
\beforeverb
\begin{verbatim}
import sqlite3

conn = sqlite3.connect('music.sqlite3')
cur = conn.cursor()

cur.execute('DROP TABLE IF EXISTS Tracks ')
cur.execute('CREATE TABLE Tracks (title TEXT, plays INTEGER)')

conn.close()
\end{verbatim}
\afterverb
%
\index{connect function}
\index{function!connect}
\index{cursor function}
\index{function!cursor}
The {\tt connect} operation makes a ``connection'' to the database 
stored in the file {\tt music.sqlite3} in the current directory.   If
the file does not exist, it will be created.  The reason this
is called a ``connection'' is that sometimes the database is stored
on a separate ``database server'' from the server on which we 
are running our application.  In our simple examples 
the database will just be a local file in the same directory
as the Python code we are running.

A {\bf cursor} is like a file handle that we can use to perform
operations on the data stored in the database.  Calling 
{\tt cursor()} is very similar conceptually to calling
{\tt open()} when dealing with text files.

\beforefig
\centerline{\includegraphics[height=1.50in]{figs2/cursor.eps}}
\afterfig

Once we have the cursor, we can begin to execute 
commands on the contents of the database using the {\tt execute()}
method.

Database commands are expressed in a special language that has 
been standardized across many different database vendors 
to allow us to learn a single database language.   The database
language is called {\bf Structured Query Language} or {\bf SQL}
for short.

\url{http://en.wikipedia.org/wiki/SQL}

In our example, we are executing two SQL commands in our database.
As a convention, we will show the SQL keywords in uppercase 
and the parts of the command that we are adding (such as the
table and column names) will be shown in lowercase.

The first SQL command removes the {\tt Tracks} table from the 
database if it exists.  This pattern is simply to allow us to 
run the same program to create the {\tt Tracks} table over 
and over again without causing an error.  Note that the
{\tt DROP TABLE} command deletes the table and all of its contents
from the database (i.e. there is no ``undo'').

\beforeverb
\begin{verbatim}
cur.execute('DROP TABLE IF EXISTS Tracks ')
\end{verbatim}
\afterverb
%
The second command creates a table named
{\tt Tracks} with a text column named {\tt title}
and an integer column named {\tt plays}.

\beforeverb
\begin{verbatim}
cur.execute('CREATE TABLE Tracks (title TEXT, plays INTEGER)')
\end{verbatim}
\afterverb
%
Now that we have created a table named {\tt Tracks}, we can put some data
into that table using the SQL {\tt INSERT} operation.   Again, we begin
by making a connection to the database and obtaining the {\tt cursor}.
We can then execute SQL commands using the cursor.

The SQL {\tt INSERT} command indicates which table we are using 
and then defines a new row by listing the fields we want to 
include {\tt (title, plays) } followed by the {\tt VALUES} we want
placed in the new row in the table.   We specify the values
as question marks {\tt (?, ?)} to indicate that the actual 
values are passed in as a tuple {\tt ( 'My Way', 15 ) } as the
second parameter to the {\tt execute()} call.

\beforeverb
\begin{verbatim}
import sqlite3

conn = sqlite3.connect('music.sqlite3')
cur = conn.cursor()

cur.execute('INSERT INTO Tracks (title, plays) VALUES ( ?, ? )', 
    ( 'Thunderstruck', 20 ) )
cur.execute('INSERT INTO Tracks (title, plays) VALUES ( ?, ? )', 
    ( 'My Way', 15 ) )
conn.commit()

print 'Tracks:'
cur.execute('SELECT title, plays FROM Tracks')
for row in cur :
   print row

cur.execute('DELETE FROM Tracks WHERE plays < 100')
conn.commit()

cur.close()
\end{verbatim}
\afterverb
%
First we {\tt INSERT} two rows into our table and use {\tt commit()} 
to force the data to be written to the database file.

\beforefig
\centerline{\includegraphics[height=1.00in]{figs2/tracks.eps}}
\afterfig

Then we use the {\tt SELECT} command
to retrieve the rows we just inserted from the table.  
On the 
{\tt SELECT} command, we indicate which columns we would like {\tt (title, plays)}
and indicate which table we want to retrieve the data from.  After we 
execute the {\tt SELECT} statement, the cursor is something we can loop through
in a {\tt for} statement.   For efficiency,
the cursor does not read all of the data from the
database when we execute the {\tt SELECT} statement.  
Instead, the data is read on-demand
as we loop through the rows in the {\tt for} statement.

The output of the program is as follows:

\beforeverb
\begin{verbatim}
Tracks:
(u'Thunderstruck', 20)
(u'My Way', 15)
\end{verbatim}
\afterverb
%
\index{Unicode}
Our {\tt for} loop finds two rows, and each row is a Python tuple with the
first value as the {\tt title} and the second value as the number of {\tt plays}.
Do not be concerned that the title strings are shown starting with 
{\tt u'}.  This is an indication that the strings are {\bf Unicode} strings
that are capable of storing non-Latin character sets.

At the very end of the program, we execute an SQL command to {\tt DELETE} 
the rows we have just created so we can run the program over and over.
The {\tt DELETE} command shows the use of a {\tt WHERE} clause that
allows us to express a selection criterion so that we can ask the database
to apply the command to only the rows that match the criterion.  In this example
the criterion happens to apply to all the rows so we empty the table
out so we can run the program repeatedly.  After the {\tt DELETE} is performed
we also call {\tt commit()} to force the data to be removed from the database.

\section{Structured Query Language (SQL) summary}

So far, we have been using the Structured Query Language in our Python
examples and have covered many of the basics of the SQL commands.
In this section, we look at the SQL language in particular
and give an overview of SQL syntax.

Since there are so many different database vendors, the Structured Query
Language (SQL) was standardized so we could communicate in a portable
manner to database systems from multiple vendors.

A relational database is made up of tables, rows, and columns.  The columns
generally have a type such as text, numeric, or date data.  When we create
a table, we indicate the names and types of the columns:

\beforeverb
\begin{verbatim}
CREATE TABLE Tracks (title TEXT, plays INTEGER)
\end{verbatim}
\afterverb
%
To insert a row into a table, we use the SQL {\tt INSERT} command:

\beforeverb
\begin{verbatim}
INSERT INTO Tracks (title, plays) VALUES ('My Way', 15)
\end{verbatim}
\afterverb
%
The {\tt INSERT} statement specifies the table name, and then a list of
the fields/columns that you would like to set in the new row, and then 
the keyword {\tt VALUES} and then a list of corresponding values 
for each of the fields.

The SQL {\tt SELECT} command is used to retrieve rows and columns from a database.
The {\tt SELECT} statement lets you specify which columns you would
like to retrieve as well as a {\tt WHERE} clause to select which 
rows you would like to see.  It also allows an optional 
{\tt ORDER BY} clause to control the sorting of the returned rows.

\beforeverb
\begin{verbatim}
SELECT * FROM Tracks WHERE title = 'My Way'
\end{verbatim}
\afterverb
%
Using \verb"*" indicates that you want the database to return all of 
the columns for each row that matches the {\tt WHERE} clause.  

Note, unlike in Python, in a SQL {\tt WHERE} clause 
we use a single equal sign 
to indicate a test for equality rather than a double equal sign.
Other logical operations allowed in a {\tt WHERE} clause include 
\verb"<",
\verb">",
\verb"<=",
\verb">=",
\verb"!=",
as well as {\tt AND} and {\tt OR} and parentheses
to build your logical expressions.

You can request that the returned rows be sorted by one of 
the fields as follows:

\beforeverb
\begin{verbatim}
SELECT title,plays FROM Tracks ORDER BY title
\end{verbatim}
\afterverb
%
To remove a row, you need a {\tt WHERE} clause on an SQL {\tt DELETE}
statement.  The {\tt WHERE} clause determines which rows are to be deleted:

\beforeverb
\begin{verbatim}
DELETE FROM Tracks WHERE title = 'My Way'
\end{verbatim}
\afterverb
%
It is possible to {\tt UPDATE} a column or columns within one or more rows
in a table using the SQL {\tt UPDATE} statement as follows:

\beforeverb
\begin{verbatim}
UPDATE Tracks SET plays = 16 WHERE title = 'My Way'
\end{verbatim}
\afterverb
%
The {\tt UPDATE} statement specifies a table and 
then a list of fields and values to change after the {\tt SET} 
keyword and then an optional {\tt WHERE} clause to select
the rows that are to be updated.  A single {\tt UPDATE} statement
will change all of the rows that match the {\tt WHERE} clause, or if 
a {\tt WHERE} clause is not specified, it performs the {\tt UPDATE}
on all of the rows in the table.

These four basic SQL commands (INSERT, SELECT, UPDATE, and DELETE) allow 
the four basic operations needed to create and maintain data.


\section{Spidering Twitter using a database}

In this section, we will create a simple spidering program that will 
go through Twitter accounts and build a database of them.
\emph{Note: Be very careful when running this program.  You do not
want to pull too much data or run the program for too long and
end up having your Twitter access shut off.}

One of the problems of any kind of spidering program is that it 
needs to be able to be stopped and restarted many times and 
you do not want to lose the data that you have retrieved so far.
You don't want to always restart your data retrieval at the
very beginning so we want to store data as we retrieve it so our
program can start back up and pick up where it left off.

We will start by retrieving one person's Twitter friends and their
statuses, looping through the list of friends, and adding each 
of the friends to a database to be retrieved in the future.  After
we process one person's Twitter friends, we check in our database
and retrieve one of the friends of the friend.  We do this over and
over, picking an ``unvisited'' person, retrieving their friend list
and adding friends we have not seen to our list for a future visit.

We also track how many times we have seen a particular friend in the
database to get some sense of ``popularity''.

By storing our list of known accounts and whether 
we have retrieved the account or not, 
and how popular the account is in a database on the disk
of the computer, we can stop and
restart our program as many times as we like.

% TODO: Add a reference to the right spot
This program is a bit complex. It is based on the code 
from the exercise earlier in the book that uses
the Twitter API.

Here is the source code for our Twitter spidering application:

\beforeverb
\begin{verbatim}
import urllib
import twurl
import json
import sqlite3

TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'

conn = sqlite3.connect('spider.sqlite3')
cur = conn.cursor()

cur.execute('''
CREATE TABLE IF NOT EXISTS Twitter 
(name TEXT, retrieved INTEGER, friends INTEGER)''')

while True:
    acct = raw_input('Enter a Twitter account, or quit: ')
    if ( acct == 'quit' ) : break
    if ( len(acct) < 1 ) :
        cur.execute('SELECT name FROM Twitter WHERE retrieved = 0 LIMIT 1')
        try:
            acct = cur.fetchone()[0]
        except:
            print 'No unretrieved Twitter accounts found'
            continue

    url = twurl.augment(TWITTER_URL, 
               {'screen_name': acct, 'count': '20'} )
    print 'Retrieving', url
    connection = urllib.urlopen(url)
    data = connection.read()
    headers = connection.info().dict
    # print 'Remaining', headers['x-rate-limit-remaining']
    js = json.loads(data)
    # print json.dumps(js, indent=4)

    cur.execute('UPDATE Twitter SET retrieved=1 WHERE name = ?', (acct, ) )

    countnew = 0
    countold = 0
    for u in js['users'] :
        friend = u['screen_name']
        print friend
        cur.execute('SELECT friends FROM Twitter WHERE name = ? LIMIT 1', 
            (friend, ) )
        try:
            count = cur.fetchone()[0]
            cur.execute('UPDATE Twitter SET friends = ? WHERE name = ?', 
                (count+1, friend) )
            countold = countold + 1
        except:
            cur.execute('''INSERT INTO Twitter (name, retrieved, friends) 
                VALUES ( ?, 0, 1 )''', ( friend, ) )
            countnew = countnew + 1
    print 'New accounts=',countnew,' revisited=',countold
    conn.commit()

cur.close()
\end{verbatim}
\afterverb
%
Our database is stored in the file {\tt spider.sqlite3} and it has one 
table named {\tt Twitter} and each row in the {\tt Twitter} table
has a column for the account name, whether we have retrieved the friends
of this account, and how many times this account has been ``friended''.

In the main loop of the program, we prompt the user for a Twitter
account name or ``quit'' to exit the program.  
If the user enters a Twitter account, we retrieve the 
list of friends and statuses
for that user and add each friend to the database if 
not already in the database.  If the friend is already in the list, 
we add one to the {\tt friends} field in the row in the database.

If the user presses enter, we look in the database for the next 
Twitter account that we have not yet retrieved and retrieve the
friends and statuses for that account, add them to the database 
or update them and increase their {\tt friends count}.

Once we retrieve the list of friends and statuses, we loop 
through all of the {\tt user} items in the returned JSON
and retrieve the \verb"screen_name" for each user.  Then we use
the {\tt SELECT } statement to see if we already have stored this
particular \verb"screen_name" in the database and retrieve the
friend count ({\tt friends}) if the record exists.

\beforeverb
\begin{verbatim}
    countnew = 0
    countold = 0
    for u in js['users'] :
        friend = u['screen_name']
        print friend
        cur.execute('SELECT friends FROM Twitter WHERE name = ? LIMIT 1', 
            (friend, ) )
        try:
            count = cur.fetchone()[0]
            cur.execute('UPDATE Twitter SET friends = ? WHERE name = ?', 
                (count+1, friend) )
            countold = countold + 1
        except:
            cur.execute('''INSERT INTO Twitter (name, retrieved, friends) 
                VALUES ( ?, 0, 1 )''', ( friend, ) )
            countnew = countnew + 1
    print 'New accounts=',countnew,' revisited=',countold
    conn.commit()
\end{verbatim}
\afterverb
%
Once the cursor executes the {\tt SELECT} statement, 
we must retrieve the rows.  We could do this with a {\tt for} 
statement, but since we are only retrieving
one row ({\tt LIMIT 1}), we can use the {\tt fetchone()} method to fetch the
first (and only) row that is the result of the {\tt SELECT} operation.  
Since {\tt fetchone()} returns the row as a {\bf tuple} (even though there is only
one field), we take the first value from the tuple using {\tt [0]} to get the 
current friend count into the variable {\tt count}.  

If this retrieval is successful, we use the SQL {\tt UPDATE} statement with a 
{\tt WHERE} clause to add one to the {\tt friends} column for the row that 
matches the friend's account.  Notice that there are two placeholders (i.e.
question marks) in the SQL, and the second parameter to the {\tt execute()} is
a two-element tuple which holds the values to be substituted into the SQL
in place of the question marks.

If the code in the {\tt try} block fails it is probably because no record
matched the {\tt WHERE name = ?} clause on the SELECT statement.  So in the
{\tt except} block, we use the SQL {\tt INSERT} statement to add the friend's
\verb"screen_name" to the table with an indication that we have not yet 
retrieved the \verb"screen_name" and setting the friend count to zero.

So the first time the program runs and we enter a Twitter account, the program
runs as follows:

\beforeverb
\begin{verbatim}
Enter a Twitter account, or quit: drchuck
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 20  revisited= 0
Enter a Twitter account, or quit: quit
\end{verbatim}
\afterverb
%
Since this is the first time we have run the program, the database
is empty and we create the database in the file {\tt spider.sqlite3} and
add a table named {\tt Twitter} to the database.  Then we retrieve
some friends and add them all to the database since the database is
empty.

At this point, we might want to write a simple database dumper
to take a look at what is in our {\tt spider.sqlite3} file:

\beforeverb
\begin{verbatim}
import sqlite3

conn = sqlite3.connect('spider.sqlite3')
cur = conn.cursor()
cur.execute('SELECT * FROM Twitter')
count = 0
for row in cur :
   print row
   count = count + 1
print count, 'rows.'
cur.close()
\end{verbatim}
\afterverb
%
This program simply opens the database and selects all of the 
columns of all of the rows in the table {\tt Twitter}, then 
loops through the rows and prints out each row.

If we run this program after the first execution of our Twitter
spider above, its output will be as follows:

\beforeverb
\begin{verbatim}
(u'opencontent', 0, 1)
(u'lhawthorn', 0, 1)
(u'steve_coppin', 0, 1)
(u'davidkocher', 0, 1)
(u'hrheingold', 0, 1)
...
20 rows.
\end{verbatim}
\afterverb
%
We see one row for each \verb"screen_name", that we 
have not retrieved the data for that \verb"screen_name" and 
everyone in the database has one friend.

Now our database reflects the retrieval of the friends of 
our first Twitter account ({\bf drchuck}).  We can run the program
again and tell it to retrieve the friends of the next 
``unprocessed'' account by simply pressing enter instead of
a Twitter account as follows:

\beforeverb
\begin{verbatim}
Enter a Twitter account, or quit: 
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 18  revisited= 2
Enter a Twitter account, or quit: 
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 17  revisited= 3
Enter a Twitter account, or quit: quit
\end{verbatim}
\afterverb
%
Since we pressed enter (i.e. we did not specify a Twitter account),
the following code is executed:

\beforeverb
\begin{verbatim}
    if ( len(acct) < 1 ) :
        cur.execute('SELECT name FROM Twitter WHERE retrieved = 0 LIMIT 1')
        try:
            acct = cur.fetchone()[0]
        except:
            print 'No unretrieved twitter accounts found'
            continue
\end{verbatim}
\afterverb
%
We use the SQL {\tt SELECT} statement to retrieve the name of the first 
({\tt LIMIT 1}) user who still has their ``have we retrieved this user''
value set to zero.  We also use the {\tt fetchone()[0]} pattern within 
a try/except block to either extract a \verb"screen_name" from the retrieved
data or put out an error message and loop back up.

If we successfully retrieved an unprocessed \verb"screen_name", we retrieve
their data as follows:

\beforeverb
\begin{verbatim}
    url = twurl.augment(TWITTER_URL, {'screen_name': acct, 'count': '20'} )
    print 'Retrieving', url
    connection = urllib.urlopen(url)
    data = connection.read()
    js = json.loads(data)

    cur.execute('UPDATE Twitter SET retrieved=1 WHERE name = ?', (acct, ) )
\end{verbatim}
\afterverb
%
Once we retrieve the data successfully, we use the {\tt UPDATE} statement 
to set the {\tt retrieved} column to one to indicate that we have completed 
the retrieval of the friends of this account.  This keeps us from re-retrieving
the same data over and over and keeps us progressing forward through the network
of Twitter friends.

If we run the friend program and press enter twice to retrieve the next 
unvisited friend's friends,
then run the dumping program, it will give us the following output:

\beforeverb
\begin{verbatim}
(u'opencontent', 1, 1)
(u'lhawthorn', 1, 1)
(u'steve_coppin', 0, 1)
(u'davidkocher', 0, 1)
(u'hrheingold', 0, 1)
...
(u'cnxorg', 0, 2)
(u'knoop', 0, 1)
(u'kthanos', 0, 2)
(u'LectureTools', 0, 1)
...
55 rows.
\end{verbatim}
\afterverb
%
We can see that we have properly recorded that we have visited 
{\tt lhawthorn} and {\tt opencontent}.  Also the accounts 
{\tt cnxorg} and {\tt kthanos} already have two followers.
Since we now have retrieved the friends of three people
({\tt drchuck}, {\tt opencontent} and {\tt lhawthorn}) our table has 55 rows 
of friends to retrieve.

Each time we run the program and press enter, it will pick the next 
unvisited account (e.g. the next account will be \verb"steve_coppin"),
retrieve their friends, mark them as retrieved and for each of the 
friends of \verb"steve_coppin", either add them to the end of the 
database, or update their friend count if they are already in the
database.

Since the program's data is all stored on disk in a database, 
the spidering activity can be suspended and resumed as many times as you 
like with no loss of data.

\section{Basic data modeling}

The real power of a relational database is when we make multiple tables
and make links between those tables.   The act of deciding how to break
up your application data into multiple tables and establishing the
relationships between the two tables is called {\bf data modeling}.  The
design document that shows the tables and their relationships 
is called a {\bf data model}.

Data modeling is a relatively sophisticated skill and we will only introduce
the most basic concepts of relational data modeling in this section.  For more
detail on data modeling you can start with:

\url{http://en.wikipedia.org/wiki/Relational_model}

Let's say for our Twitter spider application, instead of just 
counting a person's friends, we wanted to keep a list of 
all of the incoming relationships so we could find a list of 
everyone who is following a particular account.

Since everyone will potentially have many accounts that follow
them, we cannot simply add a single column to our {\tt Twitter} table. 
So we create a new table that keeps track of pairs of friends.
The following is a simple way of making such a table:

\beforeverb
\begin{verbatim}
CREATE TABLE Pals (from_friend TEXT, to_friend TEXT)
\end{verbatim}
\afterverb
%
Each time we encounter a person who {\tt drchuck} is following, we
would insert a row of the form:

\beforeverb
\begin{verbatim}
INSERT INTO Pals (from_friend,to_friend) VALUES ('drchuck', 'lhawthorn')
\end{verbatim}
\afterverb
%
As we are processing the 20 friends from the {\tt drchuck}
Twitter feed, we will insert 20 records with ``drchuck''
as the first parameter so we will end up duplicating the 
string many times in the database.

This duplication of string data violates the best practices 
for {\bf database normalization} which basically states that
we should never put the same string data in the database more than once.  
If we need the data more than once, we create a 
numeric {\bf key} for the data and reference the actual data 
using this key.

In practical terms, a string takes up a lot more 
space than an integer on the disk
and in the memory of our computer and takes more processor time
to compare and sort.  If we only have a few hundred entries 
the storage and processor time hardly matters.  But if we have 
a million people in our database and a possibility of 100 million
friend links, it is important to be able to scan data as quickly
as possible.

We will store our Twitter accounts in a table named {\tt People}
instead of the {\tt Twitter} table used in the previous example.
The {\tt People} table has an additional column 
to store the numeric key associated with the 
row for this Twitter user.   
SQLite has a feature that automatically adds the key value
for any row we insert into a table using a special type of 
data column ({\tt INTEGER PRIMARY KEY}).

We can create the {\tt People} table with this additional 
{\tt id} column as follows:

\beforeverb
\begin{verbatim}
CREATE TABLE People 
    (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)
\end{verbatim}
\afterverb
%
Notice that we are no longer maintaining a friend count in each row
of the {\tt People} table.
When we select {\tt INTEGER PRIMARY KEY} as the type of our {\tt id} column,
we are indicating that we would like SQLite to manage this column and 
assign a unique numeric key to each row we insert automatically.
We also add the keyword {\tt UNIQUE} to indicate that we will not 
allow SQLite to insert two rows with the same value for {\tt name}.

Now instead of creating the table {\tt Pals} above, we create
a table called {\tt Follows} with two integer columns
\verb"from_id" and \verb"to_id" and a constraint on the table that
the \emph{combination} of \verb"from_id" and \verb"to_id" must be unique 
in this table (i.e. we cannot insert duplicate rows) in our database.

\beforeverb
\begin{verbatim}
CREATE TABLE Follows 
    (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id) )
\end{verbatim}
\afterverb
%
When we add {\tt UNIQUE} clauses to our tables, we are communicating a set
of rules that we are asking the database to enforce when we attempt to insert
records.   We are creating these rules as a convenience in our programs as we
will see in a moment.  The rules both keep us from making mistakes and make
it simpler to write some of our code.

In essence, in creating this {\tt Follows} table, we are modelling a 
"relationship" where one person "follows" someone else
and representing it with a pair of numbers indicating that (a) the people are
connected and (b) the direction of the relationship.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/twitter.eps}}
\afterfig


\section{Programming with multiple tables}

We will now re-do the Twitter spider program using two tables, the primary
keys, and the key references as described above.  Here is the code for 
the new version of the program:

\beforeverb
\begin{verbatim}
import urllib
import twurl
import json
import sqlite3

TWITTER_URL = 'https://api.twitter.com/1.1/friends/list.json'

conn = sqlite3.connect('friends.sqlitesqlite3')
cur = conn.cursor()

cur.execute('''CREATE TABLE IF NOT EXISTS People 
    (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Follows 
    (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')

while True:
    acct = raw_input('Enter a Twitter account, or quit: ')
    if ( acct == 'quit' ) : break
    if ( len(acct) < 1 ) :
        cur.execute('''SELECT id, name FROM People 
            WHERE retrieved = 0 LIMIT 1''')
        try:
            (id, acct) = cur.fetchone()
        except:
            print 'No unretrieved Twitter accounts found'
            continue
    else:
        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1', 
            (acct, ) )
        try:
            id = cur.fetchone()[0]
        except:
            cur.execute('''INSERT OR IGNORE INTO People (name, retrieved) 
                VALUES ( ?, 0)''', ( acct, ) )
            conn.commit()
            if cur.rowcount != 1 : 
                print 'Error inserting account:',acct
                continue
            id = cur.lastrowid

    url = twurl.augment(TWITTER_URL, 
       {'screen_name': acct, 'count': '20'} )
    print 'Retrieving account', acct
    connection = urllib.urlopen(url)
    data = connection.read()
    headers = connection.info().dict
    print 'Remaining', headers['x-rate-limit-remaining']

    js = json.loads(data)
    # print json.dumps(js, indent=4)

    cur.execute('UPDATE People SET retrieved=1 WHERE name = ?', (acct, ) )

    countnew = 0
    countold = 0
    for u in js['users'] :
        friend = u['screen_name']
        print friend
        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1', 
            (friend, ) )
        try:
            friend_id = cur.fetchone()[0]
            countold = countold + 1
        except:
            cur.execute('''INSERT OR IGNORE INTO People (name, retrieved) 
                VALUES ( ?, 0)''', ( friend, ) )
            conn.commit()
            if cur.rowcount != 1 :
                print 'Error inserting account:',friend
                continue
            friend_id = cur.lastrowid
            countnew = countnew + 1
        cur.execute('''INSERT OR IGNORE INTO Follows (from_id, to_id) 
            VALUES (?, ?)''', (id, friend_id) )
    print 'New accounts=',countnew,' revisited=',countold
    conn.commit()

cur.close()
\end{verbatim}
\afterverb
%
This program is starting to get a bit complicated, but it illustrates
the patterns that we need to use when we are
using integer keys to link tables. The basic patterns are:

\begin{enumerate}

\item Creating tables with primary keys and constraints.

\item When we have a logical key for a person (i.e. account
name) and we need the {\tt id} value for the person.
Depending on whether or not the person is already
in the {\tt People} table, we either need to: 
(1) look up the person in the {\tt People} table and 
retrieve the {\tt id} value for the person 
or (2) add the person to the {\tt People} table and get the 
{\tt id} value for the newly added row.

\item Insert the row that captures the ``follows'' relationship.

\end{enumerate}

We will cover each of these in turn.

\subsection{Constraints in database tables}

As we design our table structures, we can tell the database system 
that we would like it to enforce a few rules on us.   These rules
help us from making mistakes and introducing incorrect data into 
out tables.   When we create our tables:

\beforeverb
\begin{verbatim}
cur.execute('''CREATE TABLE IF NOT EXISTS People 
    (id INTEGER PRIMARY KEY, name TEXT UNIQUE, retrieved INTEGER)''')
cur.execute('''CREATE TABLE IF NOT EXISTS Follows 
    (from_id INTEGER, to_id INTEGER, UNIQUE(from_id, to_id))''')
\end{verbatim}
\afterverb
%
We indicate that the {\tt name} column in the {\tt People} table must be
{\tt UNIQUE}.   We also indicate that the combination of the two numbers
in each row of the {\tt Follows} table must be unique.  These constraints
keep us from making mistakes such as adding the same relationship more than
once.

We can take advantage of these constraints in the following code:

\beforeverb
\begin{verbatim}
cur.execute('''INSERT OR IGNORE INTO People (name, retrieved) 
    VALUES ( ?, 0)''', ( friend, ) )
\end{verbatim}
\afterverb
%
We add the {\tt OR IGNORE} clause to our {\tt INSERT} statement to indicate
that if this particular {\tt INSERT} would cause a violation of the
``{\tt name} must be unique'' rule, the database system is allowed to ignore the 
{\tt INSERT}.  We are using the database constraint as a safety net
to make sure we don't inadvertently do something incorrect.

Similarly, the following code ensures that we don't add the 
exact same {\tt Follows} relationship twice.

\beforeverb
\begin{verbatim}
cur.execute('''INSERT OR IGNORE INTO Follows 
    (from_id, to_id) VALUES (?, ?)''', (id, friend_id) )
\end{verbatim}
\afterverb
%
Again we simply tell the database to ignore our attempted 
{\tt INSERT} if it would violate the uniqueness constraint
that we specified for the {\tt Follows} rows.

\subsection{Retrieve and/or insert a record}

When we prompt the user for a Twitter account, if the account 
exists, we must look up its {\tt id} value.  If the account
does not yet exist in the {\tt People} table, we must insert 
the record and get the {\tt id} value from the inserted
row.

This is a very common pattern and is done twice in the program above.
This code shows how we look up the {\tt id} for a 
friend's account when we have extracted a \verb"screen_name"
from a {\tt user} node in the retrieved Twitter JSON.

Since over time it will be increasingly likely that the account
will already be in the database, we first check to see if the
{\tt People} record exists using a {\tt SELECT} statement.

If all goes well\footnote{In general, when a sentence starts 
with ``if all goes well'' you will find that the code needs
to use try/except.} inside the {\tt try} section, we retrieve the
record using {\tt fetchone()} and then retrieve the
first (and only) element of the returned tuple and store it in 
\verb"friend_id".

If the {\tt SELECT} fails, the {\tt fetchone()[0]} code will fail
and control will transfer into the {\tt except} section.

\beforeverb
\begin{verbatim}
        friend = u['screen_name']
        cur.execute('SELECT id FROM People WHERE name = ? LIMIT 1',
            (friend, ) )
        try:
            friend_id = cur.fetchone()[0]
            countold = countold + 1
        except:
            cur.execute('''INSERT OR IGNORE INTO People (name, retrieved) 
                VALUES ( ?, 0)''', ( friend, ) )
            conn.commit()
            if cur.rowcount != 1 :
                print 'Error inserting account:',friend
                continue
            friend_id = cur.lastrowid
            countnew = countnew + 1
\end{verbatim}
\afterverb
%
If we end up in the {\tt except} code, it simply means that the row
was not found so we must insert the row.  We use {\tt INSERT OR 
IGNORE} just to avoid errors and then call {\tt commit()} to 
force the database to really be updated.  After the write is done, we can 
check the {\tt cur.rowcount} to see how many rows were affected.  Since
we are attempting to insert a single row, if the number of 
affected rows is something other than one, it is an error.  

If the {\tt INSERT} is successful, we can look at {\tt cur.lastrowid} 
to find out what value the database assigned to the {\tt id} column in 
our newly created row.

\subsection{Storing the friend relationship}

Once we know the key value for both the Twitter user
and the friend in the JSON, it is a simple matter to insert
the two numbers into the {\tt Follows} table
with the following code:

\beforeverb
\begin{verbatim}
cur.execute('INSERT OR IGNORE INTO Follows (from_id, to_id) VALUES (?, ?)',
    (id, friend_id) )
\end{verbatim}
\afterverb
%
Notice that we let the database take care of keeping us from ``double-inserting''
a relationship by creating the table with a uniqueness constraint and then
adding {\tt OR IGNORE} to our {\tt INSERT} statement.

Here is a sample execution of this program:

\beforeverb
\begin{verbatim}
Enter a Twitter account, or quit: 
No unretrieved Twitter accounts found
Enter a Twitter account, or quit: drchuck
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 20  revisited= 0
Enter a Twitter account, or quit: 
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 17  revisited= 3
Enter a Twitter account, or quit: 
Retrieving http://api.twitter.com/1.1/friends ...
New accounts= 17  revisited= 3
Enter a Twitter account, or quit: quit
\end{verbatim}
\afterverb
%
We started with the {\tt drchuck} account and then let the program
automatically pick the next two accounts to retrieve and add to 
our database.

The following is the first few rows in the {\tt People} 
and {\tt Follows} tables after this run is completed:

\beforeverb
\begin{verbatim}
People:
(1, u'drchuck', 1)
(2, u'opencontent', 1)
(3, u'lhawthorn', 1)
(4, u'steve_coppin', 0)
(5, u'davidkocher', 0)
55 rows.
Follows:
(1, 2)
(1, 3)
(1, 4)
(1, 5)
(1, 6)
60 rows.
\end{verbatim}
\afterverb
%
You can see the {\tt id}, {\tt name}, and {\tt visited} fields in the 
{\tt People} table and you see the numbers of both ends of 
the relationship {\tt Follows} table.   
In the {\tt People} table, we can see that the first three people
have been visited and their data has been retrieved.
The data in the {\tt Follows} table indicates that
{\tt drchuck} (user 1) is a friend to all of the people shown in the first
five rows.  This makes sense because
the first data we retrieved and stored was the Twitter friends of
{\tt drchuck}.  If you were to print more rows from the {\tt Follows} table,
you would see the friends of user two and three as well.

\section{Three kinds of keys}

Now that we have started building a data model putting our
data into multiple linked tables, and linking the rows in those
tables using {\bf keys}, we need to look at some terminology 
around keys.  There are generally three kinds of keys used 
in a database model.

\begin{itemize}

\item A {\bf logical key} is a key that the ``real world'' might use
to look up a row.   In our example data model, the {\tt name}
field is a logical key.  It is the screen name for the user 
and we indeed look up a user's row several times in the program
using the {\tt name} field.  You will often find that it makes
sense to add a {\tt UNIQUE} constraint to a logical key.  Since the 
logical key is how we look up a row from the outside world, it makes
little sense to allow multiple rows with the same value in the table.

\item A {\bf primary key} is usually a number that is assigned
automatically by the database.  It generally has no meaning outside
the program and is only used to link rows from different tables
together.  When we want to look up a row in a table, usually 
searching for the row using the primary key is the fastest 
way to find a row.  Since primary keys are integer numbers, they 
take up very little storage and can be compared or sorted very quickly.
In our data model, the {\tt id} field is an example of a primary key.

\item A {\bf foreign key} is usually a number that points to the primary key
of an associated row in a different table.  An example of a foreign
key in our data model is the \verb"from_id".  

\end{itemize}

We are using a
naming convention of always calling the primary key field name
{\tt id} and appending the suffix \verb"_id" to any field name
that is a foreign key.


\section{Using JOIN to retrieve data}

Now that we have followed the rules of database normalization
and have data separated into two tables, linked together using
primary and foreign keys, we need to be able to build a 
{\tt SELECT} that re-assembles the data across the tables.

SQL uses the {\tt JOIN} clause to re-connect these tables.  
In the {\tt JOIN} clause you specify the fields that are used 
to re-connect the rows between the tables.

The following is an example of a {\tt SELECT} with a 
{\tt JOIN} clause:

\beforeverb
\begin{verbatim}
SELECT * FROM Follows JOIN People 
    ON Follows.from_id = People.id WHERE People.id = 1
\end{verbatim}
\afterverb
%
The {\tt JOIN} clause indicates that the fields we are selecting
cross both the {\tt Follows} and {\tt People} tables.  The {\tt ON}
clause indicates how the two tables are to be joined.   Take the rows
from {\tt Follows} and append the row from {\tt People} where the
field \verb"from_id" in {\tt Follows} is the same the {\tt id} value
in the {\tt People} table.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/join.eps}}
\afterfig

The result of the JOIN is to create extra-long ``meta-rows'' which have both 
the fields from {\tt People} and the matching fields from {\tt Follows}.
Where there is more than one match between the {\tt id} field from {\tt People}
and the \verb"from_id" from {\tt People}, then JOIN creates a meta-row 
for \emph{each} of the matching pairs of rows, duplicating data as needed.

The following code demonstrates the data that we will have in the 
database after the multi-table Twitter spider program (above) has
been run several times.

\beforeverb
\begin{verbatim}
import sqlite3

conn = sqlite3.connect('spider.sqlite3')
cur = conn.cursor()

cur.execute('SELECT * FROM People')
count = 0
print 'People:'
for row in cur :
   if count < 5: print row
   count = count + 1
print count, 'rows.'

cur.execute('SELECT * FROM Follows')
count = 0
print 'Follows:'
for row in cur :
   if count < 5: print row
   count = count + 1
print count, 'rows.'

cur.execute('''SELECT * FROM Follows JOIN People 
    ON Follows.from_id = People.id WHERE People.id = 2''')
count = 0
print 'Connections for id=2:'
for row in cur :
   if count < 5: print row
   count = count + 1
print count, 'rows.'

cur.close()
\end{verbatim}
\afterverb
%
In this program, we first dump out the {\tt People}
and {\tt Follows} and then dump out a subset of the
data in the tables joined together.

Here is the output of the program:

\beforeverb
\begin{verbatim}
python twjoin.py 
People:
(1, u'drchuck', 1)
(2, u'opencontent', 1)
(3, u'lhawthorn', 1)
(4, u'steve_coppin', 0)
(5, u'davidkocher', 0)
55 rows.
Follows:
(1, 2)
(1, 3)
(1, 4)
(1, 5)
(1, 6)
60 rows.
Connections for id=2:
(2, 1, 1, u'drchuck', 1)
(2, 28, 28, u'cnxorg', 0)
(2, 30, 30, u'kthanos', 0)
(2, 102, 102, u'SomethingGirl', 0)
(2, 103, 103, u'ja_Pac', 0)
20 rows.
\end{verbatim}
\afterverb
%
You see the columns from the {\tt People} and {\tt Follows} tables and the last
set of rows is the result of the {\tt SELECT} with the {\tt JOIN} clause.

In the last select, we are looking for accounts that are friends of 
``opencontent'' (i.e. {\tt People.id=2}).

In each of the ``meta-rows'' in the last select, the first two columns are
from the {\tt Follows}
table followed by columns three through five from the {\tt People} table.  You can also
see that the second column (\verb"Follows.to_id") matches the third column
({\tt People.id}) in each of the joined-up ``meta-rows''.

\section{Summary}

This chapter has covered a lot of ground to give you an overview of the basics
of using a database in Python.   It is more complicated to write the code to use 
a database to store data than Python dictionaries or flat files so there is 
little reason to use a database unless your application truly needs the capabilities
of a database.  The situations where a database can be quite useful are: 
(1) when your application needs to make small many random updates within a large data set,
(2) when your data is so large it cannot fit in a dictionary and you need to 
look up information repeatedly, or
(3) you have a long-running process that you want to be able to stop 
and restart and retain the data from one run to the next.

You can build a simple database with a single table to suit many application 
needs, but most problems will require several tables and links/relationships
between rows in different tables.   When you start making links between 
tables, it is important to do some thoughtful design and follow the 
rules of database normalization to make the best use of the database's
capabilities.  Since the primary motivation for using a database
is that you have a large amount of data to deal with, it is important
to model your data efficiently so your programs run as fast as possible.

\section{Debugging}

One common pattern when you are developing a Python program to connect to
an SQLite database will be to run a Python program and check the
results using the SQLite Database Browser.  The browser allows you 
to quickly check to see if your program is working properly.

You must be careful because SQLite takes care to keep two programs
from changing the same data at the same time.   For example, if
you open a database in the browser and make a change to the database
and have not yet pressed the ``save'' button in the browser, the 
browser ``locks'' the database file and keeping any other program
from accessing the file.  In particular, your Python program
will not be able to access the file if it is locked.

So a solution is to make sure to either close the database browser 
or use the {\bf File} menu to close the database in the browser
before you attempt to access the database from Python to avoid
the problem of your Python code failing because the database is
locked.

\section{Glossary}

\begin{description}

\item[attribute:] One of the values within a tuple.  More commonly
called a ``column'' or ``field''.
\index{attribute}

\item[constraint:] 
When we tell the database to enforce a rule on a field or a row
in a table.  A common constraint is to insist that there can be no
duplicate values in a particular field (i.e. all the values must be unique).
\index{constraint}

\item[cursor:] A cursor allows you to execute SQL commands in a database
and retrieve data from the database.  A cursor is similar to 
a socket or file handle for network connections and files respectively.
\index{cursor}

\item[database browser:] 
A piece of software that allows you to directly connect to a database 
and manipulate the database directly without writing a program.
\index{database browser}

\item[foreign key:] A numeric key that points to the primary key of 
a row in another table.  Foreign keys establish relationships between rows
stored in different tables.
\index{foreign key}

\item[index:] Additional data that the database software maintains as rows
are inserted into a table designed to make lookups very fast.
\index{index}

\item[logical key:] A key that the ``outside world'' uses to look up a particular
row.  For example in a table of user accounts, a person's e-mail address
might be a good candidate as the logical key for the user's data. 
\index{logical key}

\item[normalization:] Designing a data model so that no data
is replicated.  We store each item of data at one place in the database
and reference it elsewhere using a foreign key.
\index{normalization}
\index{database normalization}

\item[primary key:] A numeric key assigned to each row that is used to 
refer to one row in a table from another table.  Often the database
is configured to automatically assign primary keys as rows are inserted.
\index{primary key}

\item[relation:] An area within a database that contains tuples and 
attributes.  More typically called a ``table''.
\index{relation}

\item[tuple:] A single entry in a database table that is a set 
of attributes.  More typically called ``row''.
\index{tuple}

\end{description}

\chapter{Visualizing data}

So far we have been learning the Python language and then 
learning how to use Python, the network, and databases 
to manipulate data.

In this chapter, we take a look at 
three 
complete applications that bring all of these things together
to manage and visualize data.  You  might use these applications 
as sample code to help get you started in solving a
real-world problem.

Each of the applications is a ZIP file that you can download
and extract onto your computer and execute.

\section{Building a Google map from geocoded data}
\index{Google!map}
\index{Visualization!map}

In this project, we are using the Google geocoding API
to clean up some user-entered geographic locations of 
university names and then placing the data on a Google
map.  

\beforefig
\centerline{\includegraphics[height=2.25in]{figs2/google-map.eps}}
\afterfig

To get started, download the application from:

\url{www.py4inf.com/code/geodata.zip}

The first problem to solve is that the free Google geocoding
API is rate limited to some number of requests per day.  So if you have
a lot of data you might need to stop and restart the lookup
process several times.  So we break the problem into two
phases.  

\index{cache}
In the first phase we take our input ``survey'' data in the file
{\bf where.data} and read it one line at a time, and retrieve the
geocoded information from Google and store it 
in a database {\bf geodata.sqlite}.
Before we use the geocoding API for each user-entered location, 
we simply check to see if we already have the data for that 
particular line of input.  The database is functioning as a 
local ``cache'' of our geocoding data to make sure we never ask 
Google for the same data twice.

You can re-start the process at any time by removing the file
{\bf geodata.sqlite}.

Run the {\bf geoload.py} program.   This program will read the input
lines in {\bf where.data} and for each line check to see if it is already
in the database and if we don't have the data for the location,
call the geocoding API to retrieve the data and store it in 
the database.

Here is a sample run after there is already some data in the 
database:

\beforeverb
\begin{verbatim}
Found in database  Northeastern University
Found in database  University of Hong Kong, ...
Found in database  Technion
Found in database  Viswakarma Institute, Pune, India
Found in database  UMD
Found in database  Tufts University

Resolving Monash University
Retrieving http://maps.googleapis.com/maps/api/
    geocode/json?sensor=false&address=Monash+University
Retrieved 2063 characters {    "results" : [  
{u'status': u'OK', u'results': ... }

Resolving Kokshetau Institute of Economics and Management
Retrieving http://maps.googleapis.com/maps/api/
    geocode/json?sensor=false&address=Kokshetau+Inst ...
Retrieved 1749 characters {    "results" : [  
{u'status': u'OK', u'results': ... }
...
\end{verbatim}
\afterverb
%
The first five locations are already in the database and so they 
are skipped.  The program scans to the point where it finds un-retrieved
locations and starts retrieving them.

The {\bf geoload.py} can be stopped at any time, and there is a counter 
that you can use to limit the number of calls to the geocoding
API for each run.  Given that the {\bf where.data} only has a few hundred
data items, you should not run into the daily rate limit, but if you 
had more data it might take several runs over several days to 
get your database to have all of the geocoded data for your input.

Once you have some data loaded into {\bf geodata.sqlite}, you can 
visualize the data using the {\bf geodump.py} program.  This
program reads the database and writes the file {\bf where.js}
with the location, latitude, and longitude in the form of
executable JavaScript code.   

A run of the {\bf geodump.py} program is as follows:

\beforeverb
\begin{verbatim}
Northeastern University, ... Boston, MA 02115, USA 42.3396998 -71.08975
Bradley University, 1501 ... Peoria, IL 61625, USA 40.6963857 -89.6160811
...
Technion, Viazman 87, Kesalsaba, 32000, Israel 32.7775 35.0216667
Monash University Clayton ... VIC 3800, Australia -37.9152113 145.134682
Kokshetau, Kazakhstan 53.2833333 69.3833333
...
12 records written to where.js
Open where.html to view the data in a browser
\end{verbatim}
\afterverb
%
The file {\bf where.html} consists of HTML and JavaScript to visualize 
a Google map.  It reads the most recent data in {\bf where.js} to get 
the data to be visualized.  Here is the format of the {\bf where.js} file:

\beforeverb
\begin{verbatim}
myData = [
[42.3396998,-71.08975, 'Northeastern Uni ... Boston, MA 02115'],
[40.6963857,-89.6160811, 'Bradley University, ... Peoria, IL 61625, USA'],
[32.7775,35.0216667, 'Technion, Viazman 87, Kesalsaba, 32000, Israel'],
   ...
];
\end{verbatim}
\afterverb
%
This is a JavaScript variable that contains a list of lists.  
The syntax for JavaScript list constants is very similar to 
Python so the syntax should be familiar to you.

Simply open {\bf where.html} in a browser to see the locations.  You 
can hover over each map pin to find the location that the 
geocoding API returned for the user-entered input.  If you 
cannot see any data when you open the {\bf where.html} file, you might 
want to check the JavaScript or developer console for your browser.

\section{Visualizing networks and interconnections}
\index{Google!page rank}
\index{Visualization!networks}
\index{Visualization!page rank}

In this application, we will perform some of the functions of a search
engine.   We will first spider a small subset of the web and then run
a simplified version of the Google page rank algorithm to
determine which pages are most highly connected and then visualize
the page rank and connectivity of our small corner of the web.
We will use the D3 JavaScript visualization library 
\url{http://d3js.org/} to produce the visualization output.

You can download and extract this application from:

\url{www.py4inf.com/code/pagerank.zip}

\beforefig
\centerline{\includegraphics[height=2.25in]{figs2/pagerank.eps}}
\afterfig

The first program ({\bf spider.py}) program crawls a web 
site and pulls a series of pages into the
database ({\bf spider.sqlite}), recording the links between pages.
You can restart the process at any time by removing the 
{\bf spider.sqlite} file and re-running {\bf spider.py}.

\beforeverb
\begin{verbatim}
Enter web url or enter: http://www.dr-chuck.com/
['http://www.dr-chuck.com']
How many pages:2
1 http://www.dr-chuck.com/ 12
2 http://www.dr-chuck.com/csev-blog/ 57
How many pages:
\end{verbatim}
\afterverb
%
In this sample run, we told it to crawl a website and retrieve two 
pages.  If you restart the program and tell it to crawl more
pages, it will not re-crawl any pages already in the database.  Upon 
restart it goes to a random non-crawled page and starts there.  So 
each successive run of {\bf spider.py} is additive.

\beforeverb
\begin{verbatim}
Enter web url or enter: http://www.dr-chuck.com/
['http://www.dr-chuck.com']
How many pages:3
3 http://www.dr-chuck.com/csev-blog 57
4 http://www.dr-chuck.com/dr-chuck/resume/speaking.htm 1
5 http://www.dr-chuck.com/dr-chuck/resume/index.htm 13
How many pages:
\end{verbatim}
\afterverb
%
You can have multiple starting points in the same database - 
within the program these are called ``webs''.   The spider
chooses randomly amongst all non-visited links across all
the webs as the next page to spider.

If you want to dump the contents of the {\bf spider.sqlite} file, you can 
run {\bf spdump.py} as follows:

\beforeverb
\begin{verbatim}
(5, None, 1.0, 3, u'http://www.dr-chuck.com/csev-blog')
(3, None, 1.0, 4, u'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')
(1, None, 1.0, 2, u'http://www.dr-chuck.com/csev-blog/')
(1, None, 1.0, 5, u'http://www.dr-chuck.com/dr-chuck/resume/index.htm')
4 rows.
\end{verbatim}
\afterverb
%
This shows the number of incoming links, the old page rank, the new page
rank, the id of the page, and the url of the page.  The {\bf spdump.py} program
only shows pages that have at least one incoming link to them.

Once you have a few pages in the database, you can run page rank on the
pages using the {\bf sprank.py} program.  You simply tell it how many page
rank iterations to run.

\beforeverb
\begin{verbatim}
How many iterations:2
1 0.546848992536
2 0.226714939664
[(1, 0.559), (2, 0.659), (3, 0.985), (4, 2.135), (5, 0.659)]
\end{verbatim}
\afterverb
%
You can dump the database again to see that page rank has been updated:

\beforeverb
\begin{verbatim}
(5, 1.0, 0.985, 3, u'http://www.dr-chuck.com/csev-blog')
(3, 1.0, 2.135, 4, u'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')
(1, 1.0, 0.659, 2, u'http://www.dr-chuck.com/csev-blog/')
(1, 1.0, 0.659, 5, u'http://www.dr-chuck.com/dr-chuck/resume/index.htm')
4 rows.
\end{verbatim}
\afterverb
%
You can run {\bf sprank.py} as many times as you like and it will simply refine
the page rank each time you run it.  You can even run {\bf sprank.py} a few times
and then go spider a few more pages sith {\bf spider.py} and then run {\bf sprank.py}
to re-converge the page rank values.  A search engine usually runs both the crawling and 
ranking programs all the time.

If you want to restart the page rank calculations without re-spidering the 
web pages, you can use {\bf spreset.py} and then restart {\bf sprank.py}.

\beforeverb
\begin{verbatim}
How many iterations:50
1 0.546848992536
2 0.226714939664
3 0.0659516187242
4 0.0244199333
5 0.0102096489546
6 0.00610244329379
...
42 0.000109076928206
43 9.91987599002e-05
44 9.02151706798e-05
45 8.20451504471e-05
46 7.46150183837e-05
47 6.7857770908e-05
48 6.17124694224e-05
49 5.61236959327e-05
50 5.10410499467e-05
[(512, 0.0296), (1, 12.79), (2, 28.93), (3, 6.808), (4, 13.46)]
\end{verbatim}
\afterverb
%
For each iteration of the page rank algorithm it prints the average
change in page rank per page.   The network initially is quite
unbalanced and so the individual page rank values change wildly between
iterations.
But in a few short iterations, the page rank converges.  You
should run {\bf prank.py} long enough that the page rank values converge.

If you want to visualize the current top pages in terms of page rank,
run {\bf spjson.py} to read the database and write the data for the 
most highly linked pages in JSON format to be viewed in a
web browser.

\beforeverb
\begin{verbatim}
Creating JSON output on spider.json...
How many nodes? 30
Open force.html in a browser to view the visualization
\end{verbatim}
\afterverb
%
You can view this data by opening the file {\bf force.html} in your web browser.  
This shows an automatic layout of the nodes and links.  You can click and 
drag any node and you can also double click on a node to find the URL
that is represented by the node.

If you re-run the other utilities, re-run {\bf spjson.py} 
press refresh in the browser to get the new data from {\bf spider.json}.

\section{Visualizing mail data}

Up to this point in the book, you have become quite familiar with our 
{\bf mbox-short.txt} and {\bf mbox.txt} data files.   Now it is time to take
our analysis of e-mail data to the next level.  

In the real world, sometimes you have to pull down mail data from servers
and that might take quite some time and the data might be inconsistent, 
error filled and need a lot of cleanup or adjustment.  In this section, we
work with an application that is the most complex so far and pull down nearly a 
gigabyte of data and visualize it.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/wordcloud.eps}}
\afterfig

You can download this application from:

\url{www.py4inf.com/code/gmane.zip}

We will be using data from a free e-mail list archiving service called 
\url{www.gmane.org}.  This service is very popular with open-source
projects because it provides a nice searchable archive of their 
e-mail activity.  They also have a very liberal policy regarding accessing 
their data through their API.  They have no rate limits, but ask that you 
don't overload their service and take only the data you need.  You can read
gmane's terms and conditions at this page:

\url{http://gmane.org/export.php}

{\em It is very important that you make use of the gmane.org data
responsibly by adding delays to your access of their services and spreading
long-running jobs over a longer period of time.  Do not abuse this free service
and ruin it for the rest of us.}

When the Sakai e-mail data was spidered using this software, it produced nearly 
a Gigabyte of data and took a number of runs on several days.
The file {\bf README.txt} in the above ZIP may have instructions as to how
you can download a pre-spidered copy of the {\bf content.sqlite} file for 
a majority of the Sakai e-mail corpus so you don't have to spider for 
five days just to run the programs.  If you download the pre-spidered
content, you should still run the spidering process to catch up with 
more recent messages.

The first step is to spider the gmane repository.  The base URL 
is hard-coded in the {\bf gmane.py} and is hard-coded to the Sakai
developer list.  You can spider another repository by changing that
base url.   Make sure to delete the {\bf content.sqlite} file if you 
switch the base url.  

The {\bf gmane.py} file operates as a responsible caching spider in 
that it runs slowly and retrieves one mail message per second so 
as to avoid getting throttled by gmane.   It stores all of
its data in a database and can be interrupted and re-started 
as often as needed.   It may take many hours to pull all the data
down.  So you may need to restart several times.

Here is a run of {\bf gmane.py} retrieving the last five messages of the
Sakai developer list:

\beforeverb
\begin{verbatim}
How many messages:10
http://download.gmane.org/gmane.comp.cms.sakai.devel/51410/51411 9460
    nealcaidin@sakaifoundation.org 2013-04-05 re: [building ...
http://download.gmane.org/gmane.comp.cms.sakai.devel/51411/51412 3379
    samuelgutierrezjimenez@gmail.com 2013-04-06 re: [building ...
http://download.gmane.org/gmane.comp.cms.sakai.devel/51412/51413 9903
    da1@vt.edu 2013-04-05 [building sakai] melete 2.9 oracle ...
http://download.gmane.org/gmane.comp.cms.sakai.devel/51413/51414 349265
    m.shedid@elraed-it.com 2013-04-07 [building sakai] ...
http://download.gmane.org/gmane.comp.cms.sakai.devel/51414/51415 3481
    samuelgutierrezjimenez@gmail.com 2013-04-07 re: ...
http://download.gmane.org/gmane.comp.cms.sakai.devel/51415/51416 0

Does not start with From 
\end{verbatim}
\afterverb
%
The program scans {\bf content.sqlite} from one up to the first message number not
already spidered and starts spidering at that message.  It continues spidering
until it has spidered the desired number of messages or it reaches a page
that does not appear to be a properly formatted message.

Sometimes \url{gmane.org} is missing a message.  Perhaps administrators can delete messages
or perhaps they get lost.   If your spider stops, and it seems it has hit
a missing message, go into the SQLite Manager and add a row with the missing id leaving
all the other fields blank and restart {\bf gmane.py}.   This will unstick the 
spidering process and allow it to continue.  These empty messages will be ignored in the next
phase of the process.

One nice thing is that once you have spidered all of the messages and have them in 
{\bf content.sqlite}, you can run {\bf gmane.py} again to get new messages as 
they get sent to the list.  

The {\bf content.sqlite} data is pretty raw, with an inefficient data model, 
and not compressed.
This is intentional as it allows you to look at {\bf content.sqlite}
in the SQLite Manager to debug problems with the spidering process.
It would be a bad idea to run any queries against this database as they 
would be quite slow.

The second process is to run the program {\bf gmodel.py}.  This program reads the rough/raw 
data from {\bf content.sqlite} and produces a cleaned-up and well-modeled version of the 
data in the file {\bf index.sqlite}.  The file index.sqlite will be much smaller (often 10X
smaller) than {\bf content.sqlite} because it also compresses the header and body text.

Each time {\bf gmodel.py} runs - it deletes and re-builds {\bf index.sqlite}, allowing
you to adjust its parameters and edit the mapping tables in {\bf content.sqlite} to tweak the 
data cleaning process. This is a sample run of {\bf gmodel.py}.  It prints a line out each time
250 mail messages are processed so you can see some progress happening as this program may
run for a while processing nearly a Gigabyte of mail data.

\beforeverb
\begin{verbatim}
Loaded allsenders 1588 and mapping 28 dns mapping 1
1 2005-12-08T23:34:30-06:00 ggolden22@mac.com
251 2005-12-22T10:03:20-08:00 tpamsler@ucdavis.edu
501 2006-01-12T11:17:34-05:00 lance@indiana.edu
751 2006-01-24T11:13:28-08:00 vrajgopalan@ucmerced.edu
...
\end{verbatim}
\afterverb
%

The {\bf gmodel.py} program handles a number of data cleaning tasks.

Domain names are truncated to two levels for .com, .org, .edu, and .net.
Other domain names are truncated to three levels.  So si.umich.edu becomes
umich.edu and caret.cam.ac.uk becomes cam.ac.uk.   Also e-mail addresses are
forced to lower case and some of the @gmane.org address like the following

\beforeverb
\begin{verbatim}
   arwhyte-63aXycvo3TyHXe+LvDLADg@public.gmane.org
\end{verbatim}
\afterverb
%
are converted to the real address whenever there is a matching real e-mail
address elsewhere in the message corpus.

If you look in the {\bf content.sqlite} database there are two tables that allow
you to map both domain names and individual e-mail addresses that change over 
the lifetime of the e-mail list.  For example, Steve Githens used the following
e-mail addresses as he changed jobs over the life of the Sakai developer list:

\beforeverb
\begin{verbatim}
s-githens@northwestern.edu
sgithens@cam.ac.uk
swgithen@mtu.edu
\end{verbatim}
\afterverb
%
We can add two entries to the Mapping table in {\bf content.sqlite} so 
{\bf gmodel.py} will map all three to one address:

\beforeverb
\begin{verbatim}
s-githens@northwestern.edu ->  swgithen@mtu.edu
sgithens@cam.ac.uk -> swgithen@mtu.edu
\end{verbatim}
\afterverb
%
You can also make similar entries in the DNSMapping table if there are multiple
DNS names you want mapped to a single DNS.  The following mapping was added to the Sakai data:

\beforeverb
\begin{verbatim}
iupui.edu -> indiana.edu
\end{verbatim}
\afterverb
%
So all the accounts from the various Indiana University campuses are tracked together.

You can re-run the {\bf gmodel.py} over and over as you look at the data, and add mappings
to make the data cleaner and cleaner.   When you are done, you will have a nicely
indexed version of the e-mail in {\bf index.sqlite}.   This is the file to use to do data
analysis.   With this file, data analysis will be really quick.

The first, simplest data analysis is to determine "who sent the most mail?" and "which 
organization sent the most mail"?  This is done using {\bf gbasic.py}:

\beforeverb
\begin{verbatim}
How many to dump? 5
Loaded messages= 51330 subjects= 25033 senders= 1584

Top 5 Email list participants
steve.swinsburg@gmail.com 2657
azeckoski@unicon.net 1742
ieb@tfd.co.uk 1591
csev@umich.edu 1304
david.horwitz@uct.ac.za 1184

Top 5 Email list organizations
gmail.com 7339
umich.edu 6243
uct.ac.za 2451
indiana.edu 2258
unicon.net 2055
\end{verbatim}
\afterverb
%
Note how much more quickly {\bf gbasic.py} runs compared to {\bf gmane.py}
or even {\bf gmodel.py}. They are all working on the same data, but 
{\bf gbasic.py} is using the compressed and normalized data in 
{\bf index.sqlite}.  If you have a lot of data to manage, a multi-step
process like the one in this application may take a little longer to develop,
but will save you a lot of time when you really start to explore
and visualize your data.

You can produce a simple visualization of the word frequency in the subject lines
in the file {\bf gword.py}:

\beforeverb
\begin{verbatim}
Range of counts: 33229 129
Output written to gword.js
\end{verbatim}
\afterverb
%

This produces the file {\bf gword.js} which you can visualize using
{\bf gword.htm} to produce a word cloud similar to the one at the beginning 
of this section.

A second visualization is produced  by {\bf gline.py}.  It computes e-mail 
participation by organizations over time.

\beforeverb
\begin{verbatim}
Loaded messages= 51330 subjects= 25033 senders= 1584
Top 10 Oranizations
['gmail.com', 'umich.edu', 'uct.ac.za', 'indiana.edu', 
'unicon.net', 'tfd.co.uk', 'berkeley.edu', 'longsight.com', 
'stanford.edu', 'ox.ac.uk']
Output written to gline.js
\end{verbatim}
\afterverb
%
Its output is written to {\bf gline.js} which is visualized using {\bf gline.htm}.

\beforefig
\centerline{\includegraphics[height=2.50in]{figs2/mailorg.eps}}
\afterfig

This is a relatively complex and sophisticated application and 
has features to do some real data retrieval, cleaning and visualization.

\chapter{Automating common tasks on your computer}

We have been reading data from files, networks, services,
and databases.   Python can also go through all of the 
directories and folders on your computers and read those files
as well.

In this chapter, we will write programs that scan 
through your computer and 
perform some operation on each file.  
Files are organized into directories (also called ``folders'').
Simple Python scripts
can make short work of simple tasks that must be done to 
hundreds or thousands of files
spread across a directory tree or your entire computer.

To walk through all the directories and files in a tree we use 
{\tt os.walk} and a {\tt for} loop.  This is similar to how 
{\tt open} allows us to write a loop to read the contents of a file,
{\tt socket} allows us to write a loop to read the contents of a network connection, and
{\tt urllib} allows us to open a web document and loop through its contents.

\section{File names and paths}
\label{paths}

\index{file name}
\index{path}
\index{directory}
\index{folder}

Every running program has a ``current directory,'' which is the
default directory for most operations.  
For example, when you open a file for reading, Python looks for it in the
current directory.

\index{os module}
\index{module!os}

The {\tt os} module provides functions for working with files and
directories ({\tt os} stands for ``operating system'').  {\tt os.getcwd}
returns the name of the current directory:

\index{getcwd function}
\index{function!getcwd}

\beforeverb
\begin{verbatim}
>>> import os
>>> cwd = os.getcwd()
>>> print cwd
/Users/csev
\end{verbatim}
\afterverb
%
{\tt cwd} stands for {\bf current working directory}.  The result in
this example is {\tt /Users/csev}, which is the home directory of a
user named {\tt csev}.

\index{working directory}
\index{directory!working}

A string like {\tt cwd} that identifies a file is called a path.
A {\bf relative path} starts from the current directory;
an {\bf absolute path} starts from the topmost directory in the
file system.

\index{relative path}
\index{path!relative}
\index{absolute path}
\index{path!absolute}

The paths we have seen so far are simple file names, so they are
relative to the current directory.  To find the absolute path to
a file, you can use {\tt os.path.abspath}:

\beforeverb
\begin{verbatim}
>>> os.path.abspath('memo.txt')
'/Users/csev/memo.txt'
\end{verbatim}
\afterverb
%
{\tt os.path.exists} checks
whether a file or directory exists:

\index{exists function}
\index{function!exists}

\beforeverb
\begin{verbatim}
>>> os.path.exists('memo.txt')
True
\end{verbatim}
\afterverb
%
If it exists, {\tt os.path.isdir} checks whether it's a directory:

\beforeverb
\begin{verbatim}
>>> os.path.isdir('memo.txt')
False
>>> os.path.isdir('music')
True
\end{verbatim}
\afterverb
%
Similarly, {\tt os.path.isfile} checks whether it's a file.

{\tt os.listdir} returns a list of the files (and other directories)
in the given directory:

\beforeverb
\begin{verbatim}
>>> os.listdir(cwd)
['music', 'photos', 'memo.txt']
\end{verbatim}
\afterverb
%


\section{Example: Cleaning up a photo directory}

Some time ago, I built a bit of Flickr-like software that 
received photos from my cell phone and stored those photos
on my server.  I wrote this before Flickr existed and kept 
using it after Flickr existed because
I wanted to keep original copies of my images forever.

I would also send a simple one-line text description in the MMS message
or the subject line of the e-mail message.  I stored these messages
in a text file in the same directory as the image file.   I came up 
with a directory structure based on the month, year, day and time the 
photo was taken.   The following would be an example of the naming for 
one photo and its existing description:

\beforeverb
\begin{verbatim}
./2006/03/24-03-06_2018002.jpg
./2006/03/24-03-06_2018002.txt
\end{verbatim}
\afterverb
%
After seven years, I had a lot of photos and captions.  Over the years
as I switched cell phones, sometimes my code to extract the caption from the message 
would break and add a bunch of useless data on my server instead of a caption.  

I wanted to go through these files and figure out which of the 
text files were really captions and which were junk and then delete the bad
files.  The first thing to do was to get a simple inventory of 
how many text files I had in of the sub-folders
using the following program:

\beforeverb
\begin{verbatim}
import os
count = 0
for (dirname, dirs, files) in os.walk('.'):
   for filename in files:
       if filename.endswith('.txt') :
           count = count + 1
print 'Files:', count

python txtcount.py
Files: 1917
\end{verbatim}
\afterverb
%
The key bit of code that makes this possible is the {\tt os.walk}
library in Python.  When we call {\tt os.walk} and give it a starting
directory, it will ``walk'' through all of the directories 
and sub-directories recursively.   The string ``.'' indicates
to start in the current directory and walk downward.
As it encounters each directory,
we get three values in a tuple in the body of the {\tt for} loop.  
The first value is the current
directory name, the second value is the list of sub-directories 
in the current directory, and the third value is a list of files
in the current directory.

We do not have to explicitly look into each of the sub-directories
because we can count on {\tt os.walk} to visit every 
folder eventually.  But we do want to look at each file, so 
we write a simple {\tt for} loop to examine each of the files 
in the current directory.   We check each file to see if 
it ends with ``.txt'' and then count the number of 
files through the whole directory tree that end with the
suffix ``.txt''.

Once we have a sense of how many files end with ``.txt'', the next
thing to do is try to automatically
determine in Python which files are bad and which files
are good.   So we write a simple program to print out the
files and the size of each file:

\beforeverb
\begin{verbatim}
import os
from os.path import join
for (dirname, dirs, files) in os.walk('.'):
   for filename in files:
       if filename.endswith('.txt') :
           thefile = os.path.join(dirname,filename)
           print os.path.getsize(thefile), thefile
\end{verbatim}
\afterverb
%
Now instead of just counting the files, we create 
a file name by concatenating the directory name with
the name of the file within the directory using
{\tt os.path.join}.   It is important to use 
{\tt os.path.join} instead of string concatenation 
because on Windows we use a backslash
(\verb"\") to construct file paths and on Linux
or Apple we use a forward slash (\verb"/") 
to construct file paths.  The {\tt os.path.join}
knows these differences and knows what system
we are running on and it does the proper concatenation
depending on the system.  So the same Python code
runs on either Windows or Unix-style systems.

Once we have the full file name with directory
path, we use the {\tt os.path.getsize} utility
to get the size and print it out, producing the 
following output:

\beforeverb
\begin{verbatim}
python txtsize.py
...
18 ./2006/03/24-03-06_2303002.txt
22 ./2006/03/25-03-06_1340001.txt
22 ./2006/03/25-03-06_2034001.txt
...
2565 ./2005/09/28-09-05_1043004.txt
2565 ./2005/09/28-09-05_1141002.txt
...
2578 ./2006/03/27-03-06_1618001.txt
2578 ./2006/03/28-03-06_2109001.txt
2578 ./2006/03/29-03-06_1355001.txt
...
\end{verbatim}
\afterverb
%
Scanning the output, we notice that some files are pretty short and 
a lot of the files are pretty large and the same size (2578 and 2565). 
When we take a look at a few of these larger files by hand, 
it looks like the large 
files are nothing but a generic bit of identical HTML that came 
in from mail sent to my system from my T-Mobile phone:

\beforeverb
\begin{verbatim}
<html>
        <head>
                <title>T-Mobile</title>
...
\end{verbatim}
\afterverb
%
Skimming through the file, it looks like there is no good information
in these files so we can probably delete them.

But before we delete the files, we will write a program to look for files
that are more than one line long and show the contents of the file.
We will not bother showing ourselves those files that are exactly
2578 or 2565 characters long since we know that these files have no useful
information.

So we write the following program:

\beforeverb
\begin{verbatim}
import os
from os.path import join
for (dirname, dirs, files) in os.walk('.'):
   for filename in files:
       if filename.endswith('.txt') :
           thefile = os.path.join(dirname,filename)
           size = os.path.getsize(thefile)
           if size == 2578 or size == 2565:
               continue
           fhand = open(thefile,'r')
           lines = list()
           for line in fhand:
               lines.append(line)
           fhand.close()
           if len(lines) > 1:
                print len(lines), thefile
                print lines[:4]
\end{verbatim}
\afterverb
%
We use a {\tt continue} to skip files with the two 
``bad sizes'', then open the rest of the files
and read the lines of the file into a Python list
and if the file has more than one line we print
out how many lines are in the file and print out
the first three lines.

It looks like filtering out those two bad file sizes, and assuming
that all one-line files are correct, we are down to some pretty clean
data:

\beforeverb
\begin{verbatim}
python txtcheck.py 
3 ./2004/03/22-03-04_2015.txt
['Little horse rider\r\n', '\r\n', '\r']
2 ./2004/11/30-11-04_1834001.txt
['Testing 123.\n', '\n']
3 ./2007/09/15-09-07_074202_03.txt
['\r\n', '\r\n', 'Sent from my iPhone\r\n']
3 ./2007/09/19-09-07_124857_01.txt
['\r\n', '\r\n', 'Sent from my iPhone\r\n']
3 ./2007/09/20-09-07_115617_01.txt
...
\end{verbatim}
\afterverb
%
But there is one more annoying pattern of files: 
there are some three-line files that consist of
two blank lines followed by a line that says
``Sent from my iPhone'' that have slipped 
into my data.   So we make the following change
to the program to deal with these files as well.

\beforeverb
\begin{verbatim}
           lines = list()
           for line in fhand:
               lines.append(line)
           if len(lines) == 3 and lines[2].startswith('Sent from my iPhone'):
               continue
           if len(lines) > 1:
                print len(lines), thefile
                print lines[:4]
\end{verbatim}
\afterverb
%
We simply check if we have a three-line file, and if the third 
line starts with the specified text, we skip it.

Now when we run the program, we only see four remaining 
multi-line files and all of those files look pretty reasonable:

\beforeverb
\begin{verbatim}
python txtcheck2.py 
3 ./2004/03/22-03-04_2015.txt
['Little horse rider\r\n', '\r\n', '\r']
2 ./2004/11/30-11-04_1834001.txt
['Testing 123.\n', '\n']
2 ./2006/03/17-03-06_1806001.txt
['On the road again...\r\n', '\r\n']
2 ./2006/03/24-03-06_1740001.txt
['On the road again...\r\n', '\r\n']
\end{verbatim}
\afterverb
%
If you look at the overall pattern of this program,
we have successively refined how we accept or reject
files and once we found a pattern that was ``bad'' we used
{\tt continue} to skip the bad files so we could refine
our code to find more file patterns that were bad.

Now we are getting ready to delete the files, so 
we are going to flip the logic and instead of printing out 
the remaining good files, we will print out the ``bad''
files that we are about to delete.

\beforeverb
\begin{verbatim}
import os
from os.path import join
for (dirname, dirs, files) in os.walk('.'):
   for filename in files:
       if filename.endswith('.txt') :
           thefile = os.path.join(dirname,filename)
           size = os.path.getsize(thefile)
           if size == 2578 or size == 2565:
               print 'T-Mobile:',thefile
               continue
           fhand = open(thefile,'r')
           lines = list()
           for line in fhand:
               lines.append(line)
           fhand.close()
           if len(lines) == 3 and lines[2].startswith('Sent from my iPhone'):
               print 'iPhone:', thefile
               continue
\end{verbatim}
\afterverb
%
We can now see a list of candidate files that we are about
to delete and why these files are up for deleting.
The program produces the following output:

\beforeverb
\begin{verbatim}
python txtcheck3.py
...
T-Mobile: ./2006/05/31-05-06_1540001.txt
T-Mobile: ./2006/05/31-05-06_1648001.txt
iPhone: ./2007/09/15-09-07_074202_03.txt
iPhone: ./2007/09/15-09-07_144641_01.txt
iPhone: ./2007/09/19-09-07_124857_01.txt
...
\end{verbatim}
\afterverb
%
We can spot-check these files to make sure that we did not inadvertently
end up introducing a bug in our program or perhaps our logic 
caught some files we did not want to catch.

Once we are satisfied that this is the list of files we want to delete,
we make the following change to the program:

\beforeverb
\begin{verbatim}
           if size == 2578 or size == 2565:
               print 'T-Mobile:',thefile
               os.remove(thefile)
               continue
...
           if len(lines) == 3 and lines[2].startswith('Sent from my iPhone'):
               print 'iPhone:', thefile
               os.remove(thefile)
               continue
\end{verbatim}
\afterverb
%
In this version of the program, we will both print the file out 
and remove the bad files
using {\tt os.remove}.

\beforeverb
\begin{verbatim}
python txtdelete.py 
T-Mobile: ./2005/01/02-01-05_1356001.txt
T-Mobile: ./2005/01/02-01-05_1858001.txt
...
\end{verbatim}
\afterverb
%
Just for fun, run the program a second time and it will produce no output
since the bad files are already gone.

If we re-run {\tt txtcount.py} we can see that we have removed
899 bad files:
\beforeverb
\begin{verbatim}
python txtcount.py 
Files: 1018
\end{verbatim}
\afterverb
%
In this section, we have followed a sequence where we use Python 
to first look through directories and files seeking
patterns.  We slowly use Python to help determine what we 
want to do to clean up our directories.  Once we
figure out which files are good and which files are 
not useful, we use Python to delete the files and 
perform the cleanup.

The problem you may need to solve can either be quite simple 
and might only depend on looking at the names of files,
or perhaps you need to read every single file and
look for patterns within the files.  Sometimes 
you will need to read all the files and make a change 
to some of the files.  All of these are pretty 
straightforward once you understand how {\tt os.walk}
and the other {\tt os} utilities can be used.

\section{Command line arguments}

\index{arguments}

In earlier chapters, we had a number of programs that prompted
for a file name using \verb"raw_input" and then read data 
from the file and processed the data as follows:

\beforeverb
\begin{verbatim}
name = raw_input('Enter file:')
handle = open(name, 'r')
text = handle.read()
...
\end{verbatim}
\afterverb
%
We can simplify this program a bit by taking the file name
from the command line when we start Python.  Up to now,
we simply run our Python programs and respond to the 
prompts as follows:

\beforeverb
\begin{verbatim}
python words.py
Enter file: mbox-short.txt
...
\end{verbatim}
\afterverb
%
We can place additional strings after the Python file and access
those {\bf command line arguments} in our Python program.  Here is a simple program 
that demonstrates reading arguments from the command line:

\beforeverb
\begin{verbatim}
import sys
print 'Count:', len(sys.argv)
print 'Type:', type(sys.argv)
for arg in sys.argv:
   print 'Argument:', arg
\end{verbatim}
\afterverb
%
The contents of {\tt sys.argv} are a list of strings where the first string
is the name of the Python program and the remaining strings are the arguments
on the command line after the Python file.

The following shows our program reading several command line arguments from the command
line:

\beforeverb
\begin{verbatim}
python argtest.py hello there
Count: 3
Type: <type 'list'>
Argument: argtest.py
Argument: hello
Argument: there
\end{verbatim}
\afterverb
%
There are three arguments are passed into our program as a three-element list.  
The first element of the list is the file name (argtest.py) and the others are 
the two command line arguments after the file name.

We can rewrite our program to read the file, taking the file name 
from the command line argument as follows:

\beforeverb
\begin{verbatim}
import sys

name = sys.argv[1]
handle = open(name, 'r')
text = handle.read()
print name, 'is', len(text), 'bytes'
\end{verbatim}
\afterverb
%
We take the second command line argument as the name of the file (skipping past
the program name in the {\tt [0]} entry).  We open the file and read 
the contents as follows:

\beforeverb
\begin{verbatim}
python argfile.py mbox-short.txt
mbox-short.txt is 94626 bytes
\end{verbatim}
\afterverb
%
Using command line arguments as input can make it easier to reuse your Python programs 
especially when you only need to input one or two strings.

\section{Pipes}

\index{shell}
\index{pipe}

Most operating systems provide a command-line interface,
also known as a {\bf shell}.  Shells usually provide commands
to navigate the file system and launch applications.  For
example, in Unix, you can change directories with {\tt cd},
display the contents of a directory with {\tt ls}, and launch
a web browser by typing (for example) {\tt firefox}.

\index{ls (Unix command)}
\index{Unix command!ls}

Any program that you can launch from the shell can also be
launched from Python using a {\bf pipe}.  A pipe is an object
that represents a running process.

For example, the Unix command\footnote{When using pipes to talk 
to operating system commands like {\tt ls}, it is important 
for you to know which operating system you are using and only
open pipes to commands that are supported on your operating system.}
{\tt ls -l} normally displays the
contents of the current directory (in long format).  You can
launch {\tt ls} with {\tt os.popen}:

\index{popen function}
\index{function!popen}

\beforeverb
\begin{verbatim}
>>> cmd = 'ls -l'
>>> fp = os.popen(cmd)
\end{verbatim}
\afterverb
%
The argument is a string that contains a shell command.  The
return value is a file pointer that behaves just like an open
file.  You can read the output from the {\tt ls} process one
line at a time with {\tt readline} or get the whole thing at
once with {\tt read}:

\index{readline method}
\index{method!readline}
\index{read method}
\index{method!read}

\beforeverb
\begin{verbatim}
>>> res = fp.read()
\end{verbatim}
\afterverb
%
When you are done, you close the pipe like a file:

\index{close method}
\index{method!close}

\beforeverb
\begin{verbatim}
>>> stat = fp.close()
>>> print stat
None
\end{verbatim}
\afterverb
%
The return value is the final status of the {\tt ls} process;
{\tt None} means that it ended normally (with no errors).

\section{Glossary}

\begin{description}

\item[absolute path:] A string that describes where a file or
directory is stored that starts at the ``top of the tree of directories''
so that it can be used to access the file or directory, regardless
of the current working directory.
\index{path!absolute}

\item[checksum:] See also {\bf hashing}.  The term ``checksum'' 
comes from the need to verify if data was garbled as it was 
sent across a network or written to a backup medium and then
read back in.  When the data is written or sent, the sending system
computes a checksum and also sends the checksum.  When the 
data is read or received, the receiving system re-computes
the checksum from the received data and compares it to the 
received checksum.  If the checksums do not match, we must
assume that the data was garbled as it was transferred.
\index{checksum}

\item[command line argument:] Parameters on the command line after the Python file name.


\item[current working directory:] The current directory that you 
are ``in''.  You can change your working directory using the 
{\tt cd} command on most systems in their command-line interfaces.
When you open a file in Python using just the file name with no path 
information the file must be in the current working directory
where you are running the program.
\index{directory!current}
\index{directory!working}
\index{directory!cwd}

\item[hashing:] Reading through a potentially large amount of data
and producing a unique checksum for the data.  The best hash functions
produce very few ``collisions'' where you can give two different
streams of data to the hash function and get back the same hash. 
MD5, SHA1, and SHA256 are examples of commonly used hash functions.
\index{hashing}

\item[pipe:] A pipe is a connection to a running program.  Using
a pipe, you can write a program to send data to another program
or receive data from that program.  A pipe is similar to a 
{\bf socket} except that a pipe can only be used to 
connect programs running on the same computer (i.e. not
across a network).
\index{pipe}

\item[relative path:] A string that describes where a file or
directory is stored relative to the current working 
directory.
\index{path!relative}

\item[shell:] A command-line interface to an operating system.
Also called a ``terminal program'' in some systems. In this interface
you type a command and parameters on a line and press ``enter''
to execute the command.
\index{shell}

\item[walk:] A term we use to describe the notion of visiting
the entire tree of directories, sub-directories, sub-sub-directories, 
until we have visited the all of the directories.  We call this
``walking the directory tree''.
\index{walk}

\end{description}


\section{Exercises}

\begin{ex}
\label{checksum}

\index{MP3}

In a large collection of MP3 files there may be more than one
copy of the same song, stored in different directories or with
different file names.  The goal of this exercise is to search for
these duplicates.

\begin{enumerate}

\item Write a program that walks a directory and all of its
sub-directories for all files with a given suffix (like {\tt .mp3})
and lists pairs of files with that are the same size.
Hint: Use a dictionary where the key of the dictionary is the size
of the file from {\tt  os.path.getsize} and the value in the 
dictionary is the path name concatenated with the file name.  
As you encounter each file check to see if you already have a
file that has the same size as the current file.  
If so, you have a duplicate
size file and print out the file size and the two files names 
(one from the hash and the other file you are looking at).

\index{duplicate}
\index{MD5 algorithm}
\index{algorithm!MD5}
\index{checksum}

\item Adapt the previous program to look for files that 
have duplicate content using a hashing or {\bf checksum}
algorithm.  For example,
MD5 (Message-Digest algorithm 5) takes an arbitrarily-long
``message'' and returns a 128-bit ``checksum.''  The probability
is very small that two files with different contents will
return the same checksum.

You can read about MD5 at \url{wikipedia.org/wiki/Md5}.  The 
following code snippet opens a file, reads it and computes
its checksum.

\beforeverb
\begin{verbatim}
import hashlib 
...
           fhand = open(thefile,'r')
           data = fhand.read()
           fhand.close()
           checksum = hashlib.md5(data).hexdigest()
\end{verbatim}
\afterverb
%
You should create a dictionary where the checksum is the key 
and the file name is the value.   When you compute a checksum
and it is already in the dictionary as a key, you have two files with 
duplicate content so print out the file in the dictionary
and the file you just read.  Here is some sample output
from a run in a folder of image files:

\beforeverb
\begin{verbatim}
./2004/11/15-11-04_0923001.jpg ./2004/11/15-11-04_1016001.jpg
./2005/06/28-06-05_1500001.jpg ./2005/06/28-06-05_1502001.jpg
./2006/08/11-08-06_205948_01.jpg ./2006/08/12-08-06_155318_02.jpg
\end{verbatim}
\afterverb
%
Apparently I sometimes sent the same photo more than once 
or made a copy of a photo from time to time without deleting
the original.

\end{enumerate}

\end{ex}

\appendix

\chapter{Python Programming on Windows}

In this appendix, we walk through a series of steps
so you can run Python on Windows.  There are many different 
approaches you can take, and this is just one
approach to keep things simple.

First, you need to install a programmer editor.  You
do not want to use Notepad or Microsoft Word to edit
Python programs.  Programs must be in "flat-text" files
and so you need an editor that is good at
editing text files.

Our recommended editor for Windows is NotePad++ which
can be downloaded and installed from:

\url{http://sourceforge.net/projects/notepad-plus/files/}

Then download a recent version of Python 2 from the
\url{www.python.org} web site.

\url{http://www.python.org/download/releases/2.7.5/}

Once you have installed Python, you should have a new
folder on your computer like {\tt C:{\textbackslash}Python27}.

To create a Python program, run NotePad++ from the Start Menu
and save the file with a suffix of ``.py''.  For this
exercise, put a folder on your Desktop named 
{\tt py4inf}.  It is best to keep your folder names short
and not to have any spaces in your folder or file name.

Lets make our first Python program be:

\beforeverb
\begin{verbatim}
print 'Hello Chuck'
\end{verbatim}
\afterverb
%
Except that you should change it to be your name.  Lets
save the file into {\tt Desktop{\textbackslash}py4inf{\textbackslash}prog1.py}.

The run the command line.  Different versions of Windows
do this differently:

\begin{itemize}
\item Windows Vista and Windows-7: Press {\bf Start}
and then in the command search window enter the word
{\tt command} and press enter.

\item Windows-XP: Press {\bf Start}, then {\bf Run}, and 
then enter {\tt cmd} in the dialog box and press {\bf OK}.
\end{itemize}

You will find yourself in a text window with a prompt that
tells you what folder you are currently ``in''.  

Windows Vista and Windows-7: {\tt C:{\textbackslash}Users{\textbackslash}csev}\\
Windows XP: {\tt C:{\textbackslash}Documents and Settings{\textbackslash}csev}

This is your ``home directory''.  Now we need to move into 
the folder where you have saved your Python program using
the following commands:

\beforeverb
\begin{verbatim}
C:\Users\csev\> cd Desktop
C:\Users\csev\Desktop> cd py4inf
\end{verbatim}
\afterverb
%
Then type 

\beforeverb
\begin{verbatim}
C:\Users\csev\Desktop\py4inf> dir 
\end{verbatim}
\afterverb
%
To list your files.  You should see the {\tt prog1.py} when 
you type the {\tt dir} command.

To run your program, simply type the name of your file at the 
command prompt and press enter.

\beforeverb
\begin{verbatim}
C:\Users\csev\Desktop\py4inf> prog1.py
Hello Chuck
C:\Users\csev\Desktop\py4inf> 
\end{verbatim}
\afterverb
%
You can edit the file in NotePad++, save it and then switch back
to the command line and execute the program again by typing
the file name again at the command line prompt.

If you get confused in the command line window - just close it
and start a new one.

Hint: You can also press the ``up-arrow'' in the command line to 
scroll back and run a previously entered command again.

You should also look in the preferences for NotePad++ and set it 
to expand tab characters to be four spaces.  It will save you lots
of effort looking for indentation errors.

You can also find further information on editing and running 
Python programs at \url{www.py4inf.com}.

\chapter{Python Programming on Macintosh}

In this appendix, we walk through a series of steps
so you can run Python on Macintosh.  Since Python is
already included in the Macintosh Operating system, we need to 
learn how to edit Python files and run Python programs
in the terminal window.

There approaches you can take to editing and running
Python programs, and this is just one
approach we have found to be very simple.

First, you need to install a programmer editor.  You
do not want to use TextEdit or Microsoft Word to edit
Python programs.  Programs must be in "flat-text" files
and so you need an editor that is good at
editing text files.

Our recommended editor for Macintosh is TextWrangler which
can be downloaded and installed from:

\url{http://www.barebones.com/products/TextWrangler/}

To create a Python program, run from 
{\bf TextWrangler} from your {\bf Applications} folder.

Lets make our first Python program be:

\beforeverb
\begin{verbatim}
print 'Hello Chuck'
\end{verbatim}
\afterverb
%
Except that you should change it to be your name.  
Lets save the file in a folder on your Desktop named 
{\tt py4inf}.  It is best to keep your folder names short
and not to have any spaces in your folder or file name.
Once you have made the folder, save the file 
into {\tt Desktop{\textbackslash}py4inf{\textbackslash}prog1.py}.

The run the {\bf Terminal} program.  The easiest way is to 
press the Spotlight icon (the magnifying glass) in the upper
right of your screen and enter ``terminal'' and launch the
application that comes up.

You start in your ``home directory''.  You can see the current 
directory by typing the {\tt pwd} command in the terminal window.

\beforeverb
\begin{verbatim}
67-194-80-15:~ csev$ pwd
/Users/csev
67-194-80-15:~ csev$ 
\end{verbatim}
\afterverb
%
We must be in the folder that contains your Python program 
to run the program.  We user the {\tt cd} command to move to a new 
folder and then the {\tt ls} command to list the files in the 
folder.

\beforeverb
\begin{verbatim}
67-194-80-15:~ csev$ cd Desktop
67-194-80-15:Desktop csev$ cd py4inf
67-194-80-15:py4inf csev$ ls
prog1.py
67-194-80-15:py4inf csev$ 
\end{verbatim}
\afterverb
%
To run your program, simply type the {\tt python} command followed
by the name of your file at the 
command prompt and press enter.

\beforeverb
\begin{verbatim}
67-194-80-15:py4inf csev$ python prog1.py
Hello Chuck
67-194-80-15:py4inf csev$ 
\end{verbatim}
\afterverb
%
You can edit the file in TextWrangler, save it and then switch back
to the command line and execute the program again by typing
the file name again at the command line prompt.

If you get confused in the command line window - just close it
and start a new one.

Hint: You can also press the ``up-arrow'' in the command line to 
scroll back and run a previously entered command again.

You should also look in the preferences for TextWrangler and set it 
to expand tab characters to be four spaces.  It will save you lots
of effort looking for indentation errors.

You can also find further information on editing and running 
Python programs at \url{www.py4inf.com}.



\chapter{Contributor List}
\section*{Contributor List for ``Python for Informatics''}

Bruce Shields for copy editing early drafts,
Sarah Hegge,
Steven Cherry,
Sarah Kathleen Barbarow,
Andrea Parker,
Radaphat Chongthammakun,
Megan Hixon,
Kirby Urner,
Sarah Kathleen Barbrow,
Katie Kujala,
Noah Botimer,
Emily Alinder,
Mark Thompson-Kular,
James Perry,
Eric Hofer,
Eytan Adar,
Peter Robinson,
Deborah J. Nelson,
Jonathan C. Anthony,
Eden Rassette,
Jeannette Schroeder,
Justin Feezell,
Chuanqi Li,
Gerald Gordinier,
Gavin Thomas Strassel,
Ryan Clement,
Alissa Talley,
Caitlin Holman,
Yong-Mi Kim,
Karen Stover,
Cherie Edmonds,
Maria Seiferle,
Romer Kristi D. Aranas (RK),
Grant Boyer,

% CONTRIB

\section*{Contributor List for ``Think Python''}

\index{contributors}

(Allen B. Downey)

More than 100 sharp-eyed and thoughtful readers have sent in
suggestions and corrections over the past few years.  Their
contributions, and enthusiasm for this project, have been a
huge help.

For the detail on the nature of each of the contributions from
these individuals, see the ``Think Python'' text.

Lloyd Hugh Allen,
Yvon Boulianne,
Fred Bremmer,
Jonah Cohen,
Michael Conlon,
Benoit Girard,
Courtney Gleason and Katherine Smith,
Lee Harr,
James Kaylin,
David Kershaw,
Eddie Lam,
Man-Yong Lee,
David Mayo,
Chris McAloon,
Matthew J. Moelter,
Simon Dicon Montford,
John Ouzts,
Kevin Parks,
David Pool,
Michael Schmitt,
Robin Shaw,
Paul Sleigh,
Craig T. Snydal,
Ian Thomas,
Keith Verheyden,
Peter Winstanley,
Chris Wrobel,
Moshe Zadka,
Christoph Zwerschke,
James Mayer,
Hayden McAfee,
Angel Arnal,
Tauhidul Hoque and Lex Berezhny,
Dr. Michele Alzetta,
Andy Mitchell,
Kalin Harvey,
Christopher P. Smith,
David Hutchins,
Gregor Lingl,
Julie Peters,
Florin Oprina,
D.~J.~Webre,
Ken,
Ivo Wever,
Curtis Yanko,
Ben Logan,
Jason Armstrong,
Louis Cordier,
Brian Cain,
Rob Black,
Jean-Philippe Rey at Ecole Centrale Paris,
Jason Mader at George Washington University made a number
Jan Gundtofte-Bruun,
Abel David and Alexis Dinno,
Charles Thayer,
Roger Sperberg,
Sam Bull,
Andrew Cheung,
C. Corey Capel,
Alessandra,
Wim Champagne,
Douglas Wright,
Jared Spindor,
Lin Peiheng,
Ray Hagtvedt,
Torsten H\"{u}bsch,
Inga Petuhhov,
Arne Babenhauserheide,
Mark E. Casida,
Scott Tyler,
Gordon Shephard,
Andrew Turner,
Adam Hobart,
Daryl Hammond and Sarah Zimmerman,
George Sass,
Brian Bingham,
Leah Engelbert-Fenton,
Joe Funke,
Chao-chao Chen,
Jeff Paine,
Lubos Pintes,
Gregg Lind and Abigail Heithoff,
Max Hailperin,
Chotipat Pornavalai,
Stanislaw Antol,
Eric Pashman,
Miguel Azevedo,
Jianhua Liu,
Nick King,
Martin Zuther,
Adam Zimmerman,
Ratnakar Tiwari,
Anurag Goel,
Kelli Kratzer,
Mark Griffiths,
Roydan Ongie,
Patryk Wolowiec,
Mark Chonofsky,
Russell Coleman,
Wei Huang,
Karen Barber,
Nam Nguyen,
St\'{e}phane Morin,
and
Paul Stoop.

\chapter{Copyright Detail}

This work is licensed under a 
Creative Common
Attribution-NonCommercial-ShareAlike 3.0 Unported License.
This license is 
available at
\url{creativecommons.org/licenses/by-nc-sa/3.0/}.  

I would have preferred to license the book under the less 
restrictive CC-BY-SA license.   But unfortunately there are
a few unscrupulous
organizations who search for and find freely licensed books,
and then publish and sell virtually unchanged copies of the books on a 
print on demand service such as LuLu or CreateSpace.  CreateSpace
has (thankfully) added a policy that gives the wishes of the actual 
copyright holder preference over a non-copyright holder attempting 
to publish a freely licensed work.  Unfortunately there are many 
print-on-demand services and very few have as well-considered a policy 
as CreateSpace.

Regretfully, I added the NC element to the license
this book to give me recourse in case someone tries to clone this 
book and sell it commercially.   Unfortunately, adding NC limits uses
of this material that I would like to permit.  So I have added this 
section of the document to describe specific situations where 
I am giving my permission in advance to use the material in this book
in situations that some might consider commercial.

\begin{itemize}
\item If you are printing a limited number of copies of all or part of 
this book for use in a course (e.g. like a coursepack), then 
you are granted CC-BY license to these materials for that purpose.

\item If you are a teacher at a university and you translate this book 
into a language other than English and teach using the translated book, then 
you can contact me and I will granted you a CC-BY-SA 
license to these materials with respect to the publication of your 
translation. In particular you will be permitted 
to sell the resulting translated book commercially.  
\end{itemize}

If you are intending to translate the book, you may want to contact me
so we can make sure that you have all of the related course materials so 
you can translate them as well.

Of course, you are welcome to contact me and ask for permission if these
clauses are not sufficient.  In all cases, permission to reuse and
remix this material will be granted as long as there is clear added value
or benefit to students or teachers that will accrue as a result of the 
new work.

Charles Severance\\
www.dr-chuck.com\\
Ann Arbor, MI, USA\\
September 9, 2013



\normalsize

\printindex

\clearemptydoublepage


\end{document}
